{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09a72361",
   "metadata": {},
   "source": [
    "## Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f168817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pyarrow.dataset as ds\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a7780",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d39ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Settings\n",
    "CFG = {\n",
    "    'BATCH_SIZE': 800_000,\n",
    "    'NUM_BOOST_ROUND': 2000,\n",
    "    'LEARNING_RATE': 0.05,\n",
    "    'SEED': 42,\n",
    "    'TEST_SIZE': 0.2,\n",
    "    'EARLY_STOPPING': 100,\n",
    "    'N_FOLDS': 5,\n",
    "    'OPTUNA_TRIALS': 20\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b31fa5",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55beee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_additional_features(df):\n",
    "    # 1. age_is_young (10대, 20대 구분)\n",
    "    if \"age_group\" in df.columns:\n",
    "        df[\"age_is_young\"] = df[\"age_group\"].isin([10, 20]).astype(int)\n",
    "\n",
    "    # 2. inventory_freq (지면 ID 빈도 비율)\n",
    "    if \"inventory_id\" in df.columns:\n",
    "        inv_freq = df[\"inventory_id\"].value_counts(normalize=True)\n",
    "        df[\"inventory_freq\"] = df[\"inventory_id\"].map(inv_freq)\n",
    "\n",
    "    # 3. history_mean (과거 인기도 평균)\n",
    "    history_cols = [col for col in df.columns if col.startswith(\"history_a_\")]\n",
    "    if history_cols:\n",
    "        df[\"history_mean\"] = df[history_cols].mean(axis=1)\n",
    "\n",
    "    # 4. history_trend (최근 인기도 변화량)\n",
    "    # 숫자 suffix 기준 정렬 (예: history_a_1, history_a_2, ...)\n",
    "    if history_cols:\n",
    "        sorted_history_cols = sorted(\n",
    "            history_cols,\n",
    "            key=lambda x: int(x.split(\"_\")[-1]) if x.split(\"_\")[-1].isdigit() else 0\n",
    "        )\n",
    "        if len(sorted_history_cols) >= 2:\n",
    "            last_col = sorted_history_cols[-1]\n",
    "            prev_col = sorted_history_cols[-2]\n",
    "            df[\"history_trend\"] = df[last_col] - df[prev_col]\n",
    "        else:\n",
    "            df[\"history_trend\"] = 0  # 충분한 피처가 없으면 기본값\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dbbf3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interaction_features(df, cat_cols):\n",
    "    interaction_features = []\n",
    "    for i, col1 in enumerate(cat_cols):\n",
    "        for col2 in cat_cols[i+1:]:\n",
    "            if col1 in df.columns and col2 in df.columns:\n",
    "                new_col = f\"{col1}_{col2}_interaction\"\n",
    "                df[new_col] = df[col1].astype(str) + \"_\" + df[col2].astype(str)\n",
    "                interaction_features.append(new_col)\n",
    "    le = LabelEncoder()\n",
    "    for col in interaction_features:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df, interaction_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b0b8c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_features(df):\n",
    "    if 'hour' in df.columns:\n",
    "        try:\n",
    "            df['hour'] = pd.to_numeric(df['hour'], errors='coerce').fillna(0).astype(int)\n",
    "            df['is_morning'] = ((df['hour'] >=6) & (df['hour']<12)).astype(int)\n",
    "            df['is_afternoon'] = ((df['hour']>=12)&(df['hour']<18)).astype(int)\n",
    "            df['is_evening'] = ((df['hour']>=18)&(df['hour']<24)).astype(int)\n",
    "            df['is_night'] = ((df['hour']>=0)&(df['hour']<6)).astype(int)\n",
    "            df['is_peak_hour'] = df['hour'].isin([9,10,11,14,15,16,19,20,21]).astype(int)\n",
    "            df['hour_sin'] = np.sin(2*np.pi*df['hour']/24)\n",
    "            df['hour_cos'] = np.cos(2*np.pi*df['hour']/24)\n",
    "        except:\n",
    "            pass\n",
    "    if 'day_of_week' in df.columns:\n",
    "        try:\n",
    "            df['day_of_week'] = pd.to_numeric(df['day_of_week'], errors='coerce').fillna(0).astype(int)\n",
    "            df['is_weekend'] = df['day_of_week'].isin([5,6]).astype(int)\n",
    "            df['is_monday'] = (df['day_of_week']==0).astype(int)\n",
    "            df['is_friday'] = (df['day_of_week']==4).astype(int)\n",
    "            df['dow_sin'] = np.sin(2*np.pi*df['day_of_week']/7)\n",
    "            df['dow_cos'] = np.cos(2*np.pi*df['day_of_week']/7)\n",
    "        except:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c031902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(df, feature_cols, seq_col, is_train=True, target_encoders=None):\n",
    "    cat_cols = [\"gender\",\"age_group\",\"inventory_id\",\"day_of_week\",\"hour\"]\n",
    "    df, interaction_features = create_interaction_features(df, cat_cols)\n",
    "    df = create_time_features(df)\n",
    "    df = create_additional_features(df)\n",
    "    del df['seq']\n",
    "    if is_train and 'clicked' in df.columns:\n",
    "        for col in cat_cols:\n",
    "            if col in df.columns:\n",
    "                try:\n",
    "                    target_mean = df.groupby(col)['clicked'].mean()\n",
    "                    df[f'{col}_target_mean'] = df[col].map(target_mean).fillna(df['clicked'].mean())\n",
    "                except:\n",
    "                    pass\n",
    "    elif target_encoders is not None:\n",
    "        for col, encoder_dict in target_encoders.items():\n",
    "            if col in df.columns and encoder_dict:\n",
    "                df[f'{col}_target_mean'] = df[col].map(encoder_dict).fillna(0.5)\n",
    "    new_feature_cols = [col for col in df.columns if col not in ['clicked','ID']]\n",
    "    return df, new_feature_cols\n",
    "\n",
    "def encode_categorical_features(df, cat_cols):\n",
    "    for col in cat_cols:\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                freq_encoding = df[col].value_counts().to_dict()\n",
    "                df[f'{col}_freq'] = df[col].map(freq_encoding).fillna(0)\n",
    "                df[col] = df[col].astype('category').cat.codes\n",
    "            except:\n",
    "                df[col] = 0\n",
    "                df[f'{col}_freq'] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836258a3",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09fab54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_xgb_params(X_train, y_train, X_val, y_val):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"auc\",\n",
    "            \"booster\": \"gbtree\",\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\",0.01,0.2),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\",3,12),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\",1,10),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\",0.4,1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\",0.4,1.0),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\",0.0,5.0),\n",
    "            \"lambda\": trial.suggest_float(\"lambda\",0.0,5.0),\n",
    "            \"alpha\": trial.suggest_float(\"alpha\",0.0,5.0),\n",
    "            \"seed\": CFG['SEED']\n",
    "        }\n",
    "        dtrain = xgb.DMatrix(X_train,label=y_train)\n",
    "        dval = xgb.DMatrix(X_val,label=y_val)\n",
    "        bst = xgb.train(\n",
    "            params,dtrain,num_boost_round=1000,\n",
    "            evals=[(dval,\"val\")],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        preds = bst.predict(dval)\n",
    "        auc = roc_auc_score(y_val,preds)\n",
    "        return auc\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=CFG['SEED']))\n",
    "    study.optimize(objective,n_trials=CFG['OPTUNA_TRIALS'], show_progress_bar=True)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbc0f2d",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282e3f45",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def downsample_data(df):\n",
    "    clicked_1 = df[df['clicked']==1]\n",
    "    clicked_0 = df[df['clicked']==0]\n",
    "    if len(clicked_0) > len(clicked_1)*1:\n",
    "        clicked_0 = clicked_0.sample(n=len(clicked_1)*1, random_state=CFG['SEED'])\n",
    "    return pd.concat([clicked_1,clicked_0],axis=0).sample(frac=1,random_state=CFG['SEED']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce9e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.dataset as ds\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train_xgb_with_cv(data_path):\n",
    "    dataset = ds.dataset(data_path, format=\"parquet\")\n",
    "    models = []\n",
    "    feature_names = None\n",
    "    target_encoders = {}\n",
    "    batch_num = 0\n",
    "    best_params = None\n",
    "\n",
    "    for batch in dataset.to_batches(batch_size=CFG['BATCH_SIZE']):\n",
    "        batch_num += 1\n",
    "        df = batch.to_pandas()\n",
    "\n",
    "        # 다운샘플링\n",
    "        df = downsample_data(df)\n",
    "\n",
    "        # 특징 추출\n",
    "        feature_cols = [c for c in df.columns if c not in {'clicked', 'seq', 'ID'}]\n",
    "        df, feature_cols = preprocess_features(df, feature_cols, 'seq', is_train=True)\n",
    "\n",
    "        # Target Encoding 준비\n",
    "        if batch_num == 1:\n",
    "            cat_cols = [\"gender\", \"age_group\", \"inventory_id\", \"day_of_week\", \"hour\"]\n",
    "            for col in cat_cols:\n",
    "                if col in df.columns and 'clicked' in df.columns:\n",
    "                    try:\n",
    "                        target_encoders[col] = df.groupby(col)['clicked'].mean().to_dict()\n",
    "                    except Exception:\n",
    "                        target_encoders[col] = {}\n",
    "\n",
    "        # 카테고리 인코딩\n",
    "        df = encode_categorical_features(df, [\"gender\",\"age_group\",\"inventory_id\",\"day_of_week\",\"hour\"])\n",
    "\n",
    "        available_features = [col for col in feature_cols if col in df.columns]\n",
    "        if feature_names is None:\n",
    "            feature_names = available_features.copy()\n",
    "\n",
    "        X = df[available_features].fillna(0)\n",
    "        y = df['clicked']\n",
    "\n",
    "        # 첫 배치에서 하이퍼파라미터 최적화\n",
    "        if batch_num == 1:\n",
    "            sample_size = min(50000, len(X))\n",
    "            sample_indices = np.random.choice(len(X), sample_size, replace=False)\n",
    "            X_sample = X.iloc[sample_indices]\n",
    "            y_sample = y.iloc[sample_indices]\n",
    "\n",
    "            X_temp, X_val_temp, y_temp, y_val_temp = train_test_split(\n",
    "                X_sample, y_sample, test_size=0.2,\n",
    "                random_state=CFG['SEED'], stratify=y_sample\n",
    "            )\n",
    "            best_params = optimize_xgb_params(X_temp, y_temp, X_val_temp, y_val_temp)\n",
    "            del X_temp, X_val_temp, y_temp, y_val_temp, X_sample, y_sample\n",
    "            gc.collect()\n",
    "\n",
    "        # Stratified K-Fold\n",
    "        skf = StratifiedKFold(n_splits=CFG['N_FOLDS'], shuffle=True, random_state=CFG['SEED'])\n",
    "        fold_aucs = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train, nthread=-1, feature_names=available_features)\n",
    "            dval = xgb.DMatrix(X_val, label=y_val, nthread=-1, feature_names=available_features)\n",
    "\n",
    "            params = best_params or {\n",
    "                \"objective\": \"binary:logistic\",\n",
    "                \"eval_metric\": \"auc\",\n",
    "                \"tree_method\": \"gpu_hist\",  # GPU 학습\n",
    "                \"predictor\": \"gpu_predictor\",\n",
    "                \"learning_rate\": CFG['LEARNING_RATE'],\n",
    "                \"max_depth\": 6,\n",
    "                \"subsample\": 0.8,\n",
    "                \"colsample_bytree\": 0.8,\n",
    "                \"seed\": CFG['SEED']\n",
    "            }\n",
    "\n",
    "            model = xgb.train(\n",
    "                params,\n",
    "                dtrain,\n",
    "                num_boost_round=CFG['NUM_BOOST_ROUND'],\n",
    "                evals=[(dtrain, \"train\"), (dval, \"valid\")],\n",
    "                early_stopping_rounds=CFG['EARLY_STOPPING'],\n",
    "                verbose_eval=200\n",
    "            )\n",
    "\n",
    "            val_pred = model.predict(dval)\n",
    "            fold_auc = roc_auc_score(y_val, val_pred)\n",
    "            fold_aucs.append(fold_auc)\n",
    "\n",
    "            models.append(model)\n",
    "\n",
    "            # 메모리 해제\n",
    "            del X_train, X_val, y_train, y_val, dtrain, dval\n",
    "            gc.collect()\n",
    "\n",
    "        print(f\"Batch {batch_num} Average CV AUC: {np.mean(fold_aucs):.4f} (+/- {np.std(fold_aucs):.4f})\")\n",
    "\n",
    "        del df, X, y\n",
    "        gc.collect()\n",
    "\n",
    "    return models, feature_names, target_encoders\n",
    " \n",
    "\n",
    "models, feature_names, target_encoders = train_xgb_with_cv(\"./data/train.parquet\")\n",
    "print(\"=== High Performance XGBoost CTR Prediction ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5967efc3",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870612bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_data(models,test_path,feature_names,target_encoders):\n",
    "    test_df = pd.read_parquet(test_path, engine=\"pyarrow\")\n",
    "    if 'ID' in test_df.columns:\n",
    "        test_ids = test_df['ID'].copy()\n",
    "        test_df = test_df.drop(columns=['ID'])\n",
    "    feature_cols = [c for c in test_df.columns if c!='seq']\n",
    "    test_df, feature_cols = preprocess_features(test_df, feature_cols,'seq',is_train=False,target_encoders=target_encoders)\n",
    "    test_df = encode_categorical_features(test_df, [\"gender\",\"age_group\",\"inventory_id\",\"day_of_week\",\"hour\"])\n",
    "    for feature in feature_names:\n",
    "        if feature not in test_df.columns:\n",
    "            test_df[feature]=0\n",
    "    test_features = test_df[feature_names].fillna(0)\n",
    "    predictions = np.zeros(len(test_df))\n",
    "    for model in models:\n",
    "        dtest = xgb.DMatrix(test_features)\n",
    "        predictions += model.predict(dtest)\n",
    "    predictions /= len(models)\n",
    "    return predictions\n",
    "\n",
    "test_predictions = predict_test_data(models,\"./data/test.parquet\",feature_names,target_encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5347d4e9",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb05b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['clicked'] = test_predictions\n",
    "submission.to_csv('./high_performance_xgb_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
