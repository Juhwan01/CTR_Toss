{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVIDIA Merlin XGBoost\n",
    "Complete implementation with proper memory management and debugging outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment configured\n"
     ]
    }
   ],
   "source": [
    "# Environment setup\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Environment configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ nvtabular       23.08.00        (required: ≥23.08.00)\n",
      "✅ cudf            23.10.00        (required: ≥23.10)\n",
      "✅ cupy            13.6.0          (required: ≥13.6)\n",
      "✅ xgboost         3.0.5           (required: ≥3.0)\n",
      "✅ dask            2023.9.2        (required: ≥2023.9)\n",
      "✅ pandas          1.5.3           (required: ≥1.5)\n",
      "✅ numpy           1.23.5          (required: ≥1.24)\n",
      "✅ scikit-learn    1.7.2           (required: ≥1.7)\n",
      "✅ psutil          5.9.8           (required: ≥5.9)\n",
      "✅ pyarrow         12.0.1          (required: ≥12.0)\n",
      "\n",
      "✅ All required libraries are installed and compatible!\n"
     ]
    }
   ],
   "source": [
    "# Required libraries and versions\n",
    "required_libs = {\n",
    "    'nvtabular': '23.08.00',\n",
    "    'cudf': '23.10',      # Prefix match\n",
    "    'cupy': '13.6',       # Prefix match  \n",
    "    'xgboost': '3.0',     # Minimum version\n",
    "    'dask': '2023.9',\n",
    "    'pandas': '1.5',\n",
    "    'numpy': '1.24',\n",
    "    'scikit-learn': '1.7',\n",
    "    'psutil': '5.9',      # 5.9.1 works fine (used in working code)\n",
    "    'pyarrow': '12.0'     # 12.0.1 works fine (used in working code)\n",
    "}\n",
    "\n",
    "# Check installed versions\n",
    "import importlib\n",
    "import warnings\n",
    "\n",
    "# Suppress deprecation warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    try:\n",
    "        import pkg_resources\n",
    "    except:\n",
    "        pkg_resources = None\n",
    "\n",
    "missing_libs = []\n",
    "all_good = True\n",
    "\n",
    "for lib, required_version in required_libs.items():\n",
    "    try:\n",
    "        # Map library names for import\n",
    "        import_name = lib\n",
    "        if lib == 'scikit-learn':\n",
    "            import_name = 'sklearn'\n",
    "        \n",
    "        # Check if library is installed\n",
    "        module = importlib.import_module(import_name)\n",
    "        \n",
    "        # Get installed version\n",
    "        try:\n",
    "            if hasattr(module, '__version__'):\n",
    "                installed_version = module.__version__\n",
    "            elif pkg_resources:\n",
    "                installed_version = pkg_resources.get_distribution(lib).version\n",
    "            else:\n",
    "                installed_version = 'unknown'\n",
    "        except:\n",
    "            installed_version = 'unknown'\n",
    "        \n",
    "        # Check version compatibility\n",
    "        req_major = required_version.split('.')[0]\n",
    "        inst_version_parts = installed_version.split('.')\n",
    "        inst_major = inst_version_parts[0] if installed_version != 'unknown' else ''\n",
    "        \n",
    "        # More lenient version check\n",
    "        if installed_version == 'unknown':\n",
    "            print(f\"⚠️  {lib:15} {installed_version:15} (required: ≥{required_version})\")\n",
    "        elif float(inst_major) >= float(req_major) if inst_major.isdigit() and req_major.isdigit() else installed_version.startswith(required_version[:3]):\n",
    "            print(f\"✅ {lib:15} {installed_version:15} (required: ≥{required_version})\")\n",
    "        else:\n",
    "            print(f\"⚠️  {lib:15} {installed_version:15} (required: ≥{required_version}) - but should work\")\n",
    "        \n",
    "    except ImportError:\n",
    "        missing_libs.append(lib)\n",
    "        print(f\"❌ {lib:15} NOT INSTALLED (required: ≥{required_version})\")\n",
    "        all_good = False\n",
    "\n",
    "# Report\n",
    "if missing_libs:\n",
    "    print(f\"\\n❌ Missing libraries: {', '.join(missing_libs)}\")\n",
    "    print(\"Please install them using conda or pip\")\n",
    "elif all_good:\n",
    "    print(\"\\n✅ All required libraries are installed and compatible!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully\n",
      "NVTabular version: 23.08.00\n",
      "XGBoost version: 3.0.5\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import psutil\n",
    "\n",
    "# GPU libraries\n",
    "import cudf\n",
    "import cupy as cp\n",
    "\n",
    "# NVTabular\n",
    "import nvtabular as nvt\n",
    "from nvtabular import ops\n",
    "from merlin.io import Dataset\n",
    "\n",
    "# ML libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print(\"✅ All libraries imported successfully\")\n",
    "print(f\"NVTabular version: {nvt.__version__}\")\n",
    "print(f\"XGBoost version: {xgb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Configuration:\n",
      "   Input: data/train.parquet\n",
      "   Output: data/nvt_processed_final\n",
      "   Folds: 5\n",
      "   Force reprocess: False\n"
     ]
    }
   ],
   "source": [
    "# Configuration(DATA PATH)\n",
    "TRAIN_PATH = 'data/train.parquet'\n",
    "OUTPUT_DIR = 'data/nvt_processed_final'\n",
    "TEMP_DIR = '/tmp'\n",
    "N_FOLDS = 5\n",
    "FORCE_REPROCESS = False  # Set to True to reprocess data\n",
    "\n",
    "print(f\"📋 Configuration:\")\n",
    "print(f\"   Input: {TRAIN_PATH}\")\n",
    "print(f\"   Output: {OUTPUT_DIR}\")\n",
    "print(f\"   Folds: {N_FOLDS}\")\n",
    "print(f\"   Force reprocess: {FORCE_REPROCESS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing memory functions:\n",
      "💾 CPU: 9.5GB/251.6GB (5.5%)\n",
      "💾 GPU: 0.6GB/24.0GB\n",
      "🧹 GPU memory cleared\n"
     ]
    }
   ],
   "source": [
    "# Memory management functions\n",
    "def print_memory():\n",
    "    \"\"\"Print current memory usage\"\"\"\n",
    "    mem = psutil.virtual_memory()\n",
    "    \n",
    "    try:\n",
    "        import pynvml\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "        gpu_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        gpu_used = gpu_info.used / 1024**3\n",
    "        gpu_total = gpu_info.total / 1024**3\n",
    "    except:\n",
    "        gpu_used = 0\n",
    "        gpu_total = 0\n",
    "    \n",
    "    print(f\"💾 CPU: {mem.used/1024**3:.1f}GB/{mem.total/1024**3:.1f}GB ({mem.percent:.1f}%)\")\n",
    "    print(f\"💾 GPU: {gpu_used:.1f}GB/{gpu_total:.1f}GB\")\n",
    "    return mem.percent\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Clear GPU memory\"\"\"\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    gc.collect()\n",
    "    print(\"🧹 GPU memory cleared\")\n",
    "\n",
    "# Test memory functions\n",
    "print(\"Testing memory functions:\")\n",
    "print_memory()\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Metric functions defined\n"
     ]
    }
   ],
   "source": [
    "# Metric functions\n",
    "def calculate_weighted_logloss(y_true, y_pred, eps=1e-15):\n",
    "    \"\"\"Calculate Weighted LogLoss with 50:50 class weights\"\"\"\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "    \n",
    "    mask_0 = (y_true == 0)\n",
    "    mask_1 = (y_true == 1)\n",
    "    \n",
    "    ll_0 = -np.mean(np.log(1 - y_pred[mask_0])) if mask_0.sum() > 0 else 0\n",
    "    ll_1 = -np.mean(np.log(y_pred[mask_1])) if mask_1.sum() > 0 else 0\n",
    "    \n",
    "    return 0.5 * ll_0 + 0.5 * ll_1\n",
    "\n",
    "def calculate_competition_score(y_true, y_pred):\n",
    "    \"\"\"Calculate competition score: 0.5*AP + 0.5*(1/(1+WLL))\"\"\"\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "    wll = calculate_weighted_logloss(y_true, y_pred)\n",
    "    score = 0.5 * ap + 0.5 * (1 / (1 + wll))\n",
    "    return score, ap, wll\n",
    "\n",
    "print(\"✅ Metric functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Creating XGBoost-optimized workflow...\n",
      "   Categorical: 5 columns\n",
      "   Continuous: 112 columns\n",
      "   Total features: 117\n",
      "   ✅ Workflow created (no normalization for tree models)\n",
      "✅ Workflow creation tested successfully\n"
     ]
    }
   ],
   "source": [
    "def create_workflow():\n",
    "    \"\"\"Create NVTabular workflow optimized for XGBoost\"\"\"\n",
    "    print(\"\\n🔧 Creating XGBoost-optimized workflow...\")\n",
    "    \n",
    "    # TRUE CATEGORICAL COLUMNS (only 5)\n",
    "    true_categorical = ['gender', 'age_group', 'inventory_id', 'day_of_week', 'hour']\n",
    "    \n",
    "    # CONTINUOUS COLUMNS (112 total)\n",
    "    all_continuous = (\n",
    "        [f'feat_a_{i}' for i in range(1, 19)] +  # 18\n",
    "        [f'feat_b_{i}' for i in range(1, 7)] +   # 6\n",
    "        [f'feat_c_{i}' for i in range(1, 9)] +   # 8\n",
    "        [f'feat_d_{i}' for i in range(1, 7)] +   # 6\n",
    "        [f'feat_e_{i}' for i in range(1, 11)] +  # 10\n",
    "        [f'history_a_{i}' for i in range(1, 8)] +  # 7\n",
    "        [f'history_b_{i}' for i in range(1, 31)] + # 30\n",
    "        [f'l_feat_{i}' for i in range(1, 28)]      # 27\n",
    "    )\n",
    "    \n",
    "    print(f\"   Categorical: {len(true_categorical)} columns\")\n",
    "    print(f\"   Continuous: {len(all_continuous)} columns\")\n",
    "    print(f\"   Total features: {len(true_categorical) + len(all_continuous)}\")\n",
    "    \n",
    "    # Minimal preprocessing for XGBoost\n",
    "    cat_features = true_categorical >> ops.Categorify(\n",
    "        freq_threshold=0,\n",
    "        max_size=50000\n",
    "    )\n",
    "    cont_features = all_continuous >> ops.FillMissing(fill_val=0)\n",
    "    \n",
    "    workflow = nvt.Workflow(cat_features + cont_features + ['clicked'])\n",
    "    \n",
    "    print(\"   ✅ Workflow created (no normalization for tree models)\")\n",
    "    return workflow\n",
    "\n",
    "# Test workflow creation\n",
    "test_workflow = create_workflow()\n",
    "print(\"✅ Workflow creation tested successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🚀 NVTabular Data Processing\n",
      "======================================================================\n",
      "✅ Using existing processed data from data/nvt_processed_final\n"
     ]
    }
   ],
   "source": [
    "def process_data():\n",
    "    \"\"\"Process data with NVTabular\"\"\"\n",
    "    import shutil\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🚀 NVTabular Data Processing\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Check if already processed\n",
    "    if os.path.exists(OUTPUT_DIR) and not FORCE_REPROCESS:\n",
    "        try:\n",
    "            test_dataset = Dataset(OUTPUT_DIR, engine='parquet')\n",
    "            print(f\"✅ Using existing processed data from {OUTPUT_DIR}\")\n",
    "            return OUTPUT_DIR\n",
    "        except:\n",
    "            print(f\"⚠️ Existing data corrupted, reprocessing...\")\n",
    "            shutil.rmtree(OUTPUT_DIR)\n",
    "    \n",
    "    # Clear existing if needed\n",
    "    if os.path.exists(OUTPUT_DIR):\n",
    "        print(f\"🗑️ Removing existing directory {OUTPUT_DIR}\")\n",
    "        shutil.rmtree(OUTPUT_DIR)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    initial_mem = print_memory()\n",
    "    \n",
    "    # Prepare data without 'seq' column\n",
    "    temp_path = f'{TEMP_DIR}/train_no_seq.parquet'\n",
    "    if not os.path.exists(temp_path):\n",
    "        print(\"\\n📋 Creating temp file without 'seq' column...\")\n",
    "        pf = pq.ParquetFile(TRAIN_PATH)\n",
    "        cols = [c for c in pf.schema.names if c != 'seq']\n",
    "        print(f\"   Total columns: {len(pf.schema.names)}\")\n",
    "        print(f\"   Using columns: {len(cols)} (excluded 'seq')\")\n",
    "        \n",
    "        df = pd.read_parquet(TRAIN_PATH, columns=cols)\n",
    "        print(f\"   Loaded {len(df):,} rows\")\n",
    "        df.to_parquet(temp_path, index=False)\n",
    "        del df\n",
    "        gc.collect()\n",
    "        print(\"   ✅ Temp file created\")\n",
    "    else:\n",
    "        print(f\"✅ Using existing temp file: {temp_path}\")\n",
    "    \n",
    "    # Create dataset with small partitions\n",
    "    print(\"\\n📦 Creating NVTabular Dataset...\")\n",
    "    print(\"   Using 32MB partitions for memory efficiency\")\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    dataset = Dataset(\n",
    "        temp_path,\n",
    "        engine='parquet',\n",
    "        part_size='32MB'  #change size based on your environment\n",
    "    )\n",
    "    print(\"   ✅ Dataset created\")\n",
    "    \n",
    "    # Create and fit workflow\n",
    "    print(\"\\n📊 Fitting workflow...\")\n",
    "    workflow = create_workflow()\n",
    "    workflow.fit(dataset)\n",
    "    print(\"   ✅ Workflow fitted\")\n",
    "    \n",
    "    # Transform and save\n",
    "    print(f\"\\n💾 Transforming and saving to {OUTPUT_DIR}...\")\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    try:\n",
    "        workflow.transform(dataset).to_parquet(\n",
    "            output_path=OUTPUT_DIR,\n",
    "            shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "            out_files_per_proc=8\n",
    "        )\n",
    "        \n",
    "        workflow_path = f'{OUTPUT_DIR}/workflow'\n",
    "        workflow.save(workflow_path)\n",
    "        print(f\"   ✅ Data processed and saved\")\n",
    "        print(f\"   ✅ Workflow saved to {workflow_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during processing: {e}\")\n",
    "        if os.path.exists(OUTPUT_DIR):\n",
    "            shutil.rmtree(OUTPUT_DIR)\n",
    "        raise\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    final_mem = print_memory()\n",
    "    \n",
    "    print(f\"\\n✅ Processing complete!\")\n",
    "    print(f\"   Time: {elapsed:.1f}s\")\n",
    "    print(f\"   Memory increase: +{final_mem - initial_mem:.1f}%\")\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    return OUTPUT_DIR\n",
    "\n",
    "# Process data\n",
    "processed_dir = process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM ensemble cross-validation...\n",
      "\n",
      "======================================================================\n",
      "🔄 LightGBM Boosting Type Ensemble Cross-Validation\n",
      "======================================================================\n",
      "\n",
      "📦 Loading processed data...\n",
      "   Converting to GPU DataFrame...\n",
      "   ✅ Loaded 10,704,179 rows x 118 columns\n",
      "   Time: 1.8s\n",
      "💾 CPU: 19.5GB/251.6GB (9.5%)\n",
      "💾 GPU: 5.8GB/24.0GB\n",
      "\n",
      "📊 Preparing data for LightGBM...\n",
      "   Shape: (10704179, 117)\n",
      "   Features: 117\n",
      "   Samples: 10,704,179\n",
      "\n",
      "📊 Class distribution:\n",
      "   Positive ratio: 0.0191\n",
      "   Scale pos weight: 51.43\n",
      "\n",
      "🔄 Starting cross-validation...\n",
      "\n",
      "📍 Fold 1/5\n",
      "   Train: 8,563,343 | Val: 2,140,836\n",
      "   🚀 Training GBDT...\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "\n",
    "def run_cv_lgbm_ensemble(processed_dir, n_folds=5): \n",
    "    \"\"\"Run stratified cross-validation with LightGBM ensemble of different boosting types\"\"\" \n",
    "    print(\"\\n\" + \"=\"*70) \n",
    "    print(\"🔄 LightGBM Boosting Type Ensemble Cross-Validation\") \n",
    "    print(\"=\"*70) \n",
    "     \n",
    "    # Load processed data \n",
    "    print(\"\\n📦 Loading processed data...\") \n",
    "    start_load = time.time() \n",
    "     \n",
    "    try: \n",
    "        dataset = Dataset(processed_dir, engine='parquet', part_size='256MB') \n",
    "        print(\"   Converting to GPU DataFrame...\") \n",
    "        gdf = dataset.to_ddf().compute() \n",
    "        print(f\"   ✅ Loaded {len(gdf):,} rows x {len(gdf.columns)} columns\") \n",
    "        print(f\"   Time: {time.time() - start_load:.1f}s\") \n",
    "    except Exception as e: \n",
    "        print(f\"❌ Error loading data: {e}\") \n",
    "        return None \n",
    "     \n",
    "    print_memory() \n",
    "     \n",
    "    # Prepare data \n",
    "    print(\"\\n📊 Preparing data for LightGBM...\") \n",
    "    y = gdf['clicked'].to_numpy() \n",
    "    X = gdf.drop('clicked', axis=1) \n",
    "     \n",
    "    # Convert to float32 \n",
    "    for col in X.columns: \n",
    "        if X[col].dtype != 'float32': \n",
    "            X[col] = X[col].astype('float32') \n",
    "     \n",
    "    X_np = X.to_numpy() \n",
    "    print(f\"   Shape: {X_np.shape}\") \n",
    "    print(f\"   Features: {X.shape[1]}\") \n",
    "    print(f\"   Samples: {X.shape[0]:,}\") \n",
    "     \n",
    "    # Class distribution \n",
    "    pos_ratio = y.mean() \n",
    "    scale_pos_weight = (1 - pos_ratio) / pos_ratio \n",
    "    print(f\"\\n📊 Class distribution:\") \n",
    "    print(f\"   Positive ratio: {pos_ratio:.4f}\") \n",
    "    print(f\"   Scale pos weight: {scale_pos_weight:.2f}\") \n",
    "     \n",
    "    del X, gdf \n",
    "    clear_gpu_memory() \n",
    "     \n",
    "    # Define different boosting types and their parameters\n",
    "    boosting_configs = {\n",
    "        'gbdt': {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'device_type': 'cpu',\n",
    "            'max_depth': 8,\n",
    "            'learning_rate': 0.1,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'scale_pos_weight': scale_pos_weight,\n",
    "            'verbose': -1,\n",
    "            'seed': 42,\n",
    "            'num_leaves': 255,\n",
    "            'min_data_in_leaf': 100,\n",
    "        },\n",
    "        'dart': {\n",
    "            'boosting_type': 'dart',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'device_type': 'cpu',\n",
    "            'max_depth': 8,\n",
    "            'learning_rate': 0.1,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'scale_pos_weight': scale_pos_weight,\n",
    "            'verbose': -1,\n",
    "            'seed': 42,\n",
    "            'num_leaves': 255,\n",
    "            'min_data_in_leaf': 100,\n",
    "            'drop_rate': 0.1,\n",
    "            'max_drop': 50,\n",
    "            'skip_drop': 0.5,\n",
    "        },\n",
    "        'goss': {\n",
    "            'boosting_type': 'goss',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'device_type': 'cpu',\n",
    "            'max_depth': 8,\n",
    "            'learning_rate': 0.1,\n",
    "            'feature_fraction': 0.8,\n",
    "            'scale_pos_weight': scale_pos_weight,\n",
    "            'verbose': -1,\n",
    "            'seed': 42,\n",
    "            'num_leaves': 255,\n",
    "            'min_data_in_leaf': 100,\n",
    "            'top_rate': 0.2,\n",
    "            'other_rate': 0.1,\n",
    "        }\n",
    "    }\n",
    "     \n",
    "    # Cross-validation \n",
    "    print(\"\\n🔄 Starting cross-validation...\") \n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42) \n",
    "     \n",
    "    # Store results for each boosting type\n",
    "    all_results = {boosting_type: {'scores': [], 'ap': [], 'wll': [], 'predictions': []} \n",
    "                   for boosting_type in boosting_configs.keys()}\n",
    "    ensemble_results = {'scores': [], 'ap': [], 'wll': []}\n",
    "     \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_np, y), 1): \n",
    "        print(f\"\\n📍 Fold {fold}/{n_folds}\") \n",
    "        fold_start = time.time() \n",
    "         \n",
    "        print(f\"   Train: {len(train_idx):,} | Val: {len(val_idx):,}\") \n",
    "        \n",
    "        # Create LightGBM datasets\n",
    "        train_data = lgb.Dataset(X_np[train_idx], label=y[train_idx])\n",
    "        val_data = lgb.Dataset(X_np[val_idx], label=y[val_idx], reference=train_data)\n",
    "        \n",
    "        fold_predictions = {}\n",
    "        \n",
    "        # Train each boosting type\n",
    "        for boosting_type, params in boosting_configs.items():\n",
    "            print(f\"   🚀 Training {boosting_type.upper()}...\")\n",
    "            boosting_start = time.time()\n",
    "            \n",
    "            # Train model\n",
    "            model = lgb.train(\n",
    "                params,\n",
    "                train_data,\n",
    "                num_boost_round=200,\n",
    "                valid_sets=[val_data],\n",
    "                callbacks=[\n",
    "                    lgb.early_stopping(20, verbose=False),\n",
    "                    lgb.log_evaluation(0)  # No verbose output\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Predict\n",
    "            y_pred = model.predict(X_np[val_idx], num_iteration=model.best_iteration)\n",
    "            fold_predictions[boosting_type] = y_pred\n",
    "            \n",
    "            # Evaluate individual model\n",
    "            score, ap, wll = calculate_competition_score(y[val_idx], y_pred)\n",
    "            \n",
    "            all_results[boosting_type]['scores'].append(score)\n",
    "            all_results[boosting_type]['ap'].append(ap)\n",
    "            all_results[boosting_type]['wll'].append(wll)\n",
    "            all_results[boosting_type]['predictions'].append(y_pred)\n",
    "            \n",
    "            print(f\"      {boosting_type.upper()} - Score: {score:.6f}, AP: {ap:.6f}, WLL: {wll:.6f}\")\n",
    "            print(f\"      Best iteration: {model.best_iteration}, Time: {time.time() - boosting_start:.1f}s\")\n",
    "            \n",
    "            del model\n",
    "            clear_gpu_memory()\n",
    "        \n",
    "        # Create ensemble prediction (simple average)\n",
    "        print(\"   🎯 Creating ensemble...\")\n",
    "        ensemble_pred = np.mean([fold_predictions[bt] for bt in boosting_configs.keys()], axis=0)\n",
    "        \n",
    "        # Evaluate ensemble\n",
    "        ensemble_score, ensemble_ap, ensemble_wll = calculate_competition_score(y[val_idx], ensemble_pred)\n",
    "        \n",
    "        ensemble_results['scores'].append(ensemble_score)\n",
    "        ensemble_results['ap'].append(ensemble_ap)\n",
    "        ensemble_results['wll'].append(ensemble_wll)\n",
    "        \n",
    "        print(f\"   🏆 ENSEMBLE - Score: {ensemble_score:.6f}, AP: {ensemble_ap:.6f}, WLL: {ensemble_wll:.6f}\")\n",
    "        print(f\"   ⏱️ Total fold time: {time.time() - fold_start:.1f}s\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del train_data, val_data\n",
    "        clear_gpu_memory()\n",
    "     \n",
    "    # Final results \n",
    "    print(\"\\n\" + \"=\"*80) \n",
    "    print(\"📊 Final Cross-Validation Results\") \n",
    "    print(\"=\"*80) \n",
    "    \n",
    "    # Individual boosting type results\n",
    "    print(\"\\n📈 Individual Boosting Type Results:\")\n",
    "    for boosting_type in boosting_configs.keys():\n",
    "        results = all_results[boosting_type]\n",
    "        mean_score = np.mean(results['scores'])\n",
    "        std_score = np.std(results['scores'])\n",
    "        mean_ap = np.mean(results['ap'])\n",
    "        std_ap = np.std(results['ap'])\n",
    "        mean_wll = np.mean(results['wll'])\n",
    "        std_wll = np.std(results['wll'])\n",
    "        \n",
    "        print(f\"\\n🔹 {boosting_type.upper()}:\")\n",
    "        print(f\"   Competition Score: {mean_score:.6f} ± {std_score:.6f}\")\n",
    "        print(f\"   Average Precision: {mean_ap:.6f} ± {std_ap:.6f}\")\n",
    "        print(f\"   Weighted LogLoss:  {mean_wll:.6f} ± {std_wll:.6f}\")\n",
    "        print(f\"   All scores: {[f'{s:.6f}' for s in results['scores']]}\")\n",
    "    \n",
    "    # Ensemble results\n",
    "    print(f\"\\n🏆 ENSEMBLE RESULTS:\")\n",
    "    print(f\"   Competition Score: {np.mean(ensemble_results['scores']):.6f} ± {np.std(ensemble_results['scores']):.6f}\")\n",
    "    print(f\"   Average Precision: {np.mean(ensemble_results['ap']):.6f} ± {np.std(ensemble_results['ap']):.6f}\")\n",
    "    print(f\"   Weighted LogLoss:  {np.mean(ensemble_results['wll']):.6f} ± {np.std(ensemble_results['wll']):.6f}\")\n",
    "    print(f\"   All scores: {[f'{s:.6f}' for s in ensemble_results['scores']]}\")\n",
    "    \n",
    "    # Performance comparison\n",
    "    print(f\"\\n📊 Performance Summary:\")\n",
    "    best_individual = max(boosting_configs.keys(), \n",
    "                         key=lambda bt: np.mean(all_results[bt]['scores']))\n",
    "    best_individual_score = np.mean(all_results[best_individual]['scores'])\n",
    "    ensemble_score = np.mean(ensemble_results['scores'])\n",
    "    \n",
    "    print(f\"   Best individual: {best_individual.upper()} ({best_individual_score:.6f})\")\n",
    "    print(f\"   Ensemble score: {ensemble_score:.6f}\")\n",
    "    print(f\"   Improvement: {ensemble_score - best_individual_score:+.6f}\")\n",
    "    \n",
    "    return ensemble_results, all_results\n",
    "\n",
    "def train_final_ensemble_models(processed_dir, boosting_configs):\n",
    "    \"\"\"Train final ensemble models on full dataset\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🎯 Training Final Ensemble Models\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load data (same as before)\n",
    "    dataset = Dataset(processed_dir, engine='parquet', part_size='256MB')\n",
    "    gdf = dataset.to_ddf().compute()\n",
    "    \n",
    "    y = gdf['clicked'].to_numpy()\n",
    "    X = gdf.drop('clicked', axis=1)\n",
    "    \n",
    "    for col in X.columns:\n",
    "        if X[col].dtype != 'float32':\n",
    "            X[col] = X[col].astype('float32')\n",
    "    \n",
    "    X_np = X.to_numpy()\n",
    "    del X, gdf\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    # Train final models\n",
    "    final_models = {}\n",
    "    train_data = lgb.Dataset(X_np, label=y)\n",
    "    \n",
    "    for boosting_type, params in boosting_configs.items():\n",
    "        print(f\"\\n🚀 Training final {boosting_type.upper()} model...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=200,\n",
    "            callbacks=[lgb.log_evaluation(0)]\n",
    "        )\n",
    "        \n",
    "        final_models[boosting_type] = model\n",
    "        print(f\"   ✅ Completed in {time.time() - start_time:.1f}s\")\n",
    "    \n",
    "    return final_models\n",
    "\n",
    "# Run cross-validation with ensemble\n",
    "print(\"Starting LightGBM ensemble cross-validation...\")\n",
    "ensemble_results, individual_results = run_cv_lgbm_ensemble(processed_dir, N_FOLDS)\n",
    "\n",
    "# Train final models for inference\n",
    "boosting_configs = {\n",
    "    'gbdt': {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'device_type': 'cpu',\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': 42,\n",
    "        'num_leaves': 255,\n",
    "        'min_data_in_leaf': 100,\n",
    "    },\n",
    "    'dart': {\n",
    "        'boosting_type': 'dart',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'device_type': 'cpu',\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': 42,\n",
    "        'num_leaves': 255,\n",
    "        'min_data_in_leaf': 100,\n",
    "        'drop_rate': 0.1,\n",
    "        'max_drop': 50,\n",
    "        'skip_drop': 0.5,\n",
    "    },\n",
    "    'goss': {\n",
    "        'boosting_type': 'goss',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'device_type': 'cpu',\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'verbose': -1,\n",
    "        'seed': 42,\n",
    "        'num_leaves': 255,\n",
    "        'min_data_in_leaf': 100,\n",
    "        'top_rate': 0.2,\n",
    "        'other_rate': 0.1,\n",
    "    }\n",
    "}\n",
    "\n",
    "final_models = train_final_ensemble_models(processed_dir, boosting_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉\n",
      "COMPLETE!\n",
      "🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉\n",
      "\n",
      "✅ Final CV Score: 0.353147 ± 0.000375\n",
      "✅ Full dataset processed (10.7M rows)\n",
      "✅ XGBoost-optimized preprocessing (no normalization)\n",
      "✅ Memory-efficient with small partitions\n",
      "======================================================================\n",
      "🧹 GPU memory cleared\n",
      "\n",
      "🧹 Final cleanup complete\n",
      "💾 CPU: 9.7GB/251.6GB (5.6%)\n",
      "💾 GPU: 0.6GB/24.0GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ensemble_results:\n",
    "    cv_scores = ensemble_results['scores']\n",
    "    print(\"\\n\" + \"🎉\"*35)\n",
    "    print(\"COMPLETE!\")\n",
    "    print(\"🎉\"*35)\n",
    "    print(f\"\\n✅ Final CV Score: {np.mean(cv_scores):.6f} ± {np.std(cv_scores):.6f}\")\n",
    "    print(\"✅ Full dataset processed (10.7M rows)\")\n",
    "    print(\"✅ LightGBM-ensemble preprocessing (GBDT+DART+GOSS)\")\n",
    "    print(\"✅ Memory-efficient with small partitions\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"\\n⚠️ Cross-validation did not complete. Please check for errors above.\")\n",
    "\n",
    "# Final cleanup\n",
    "clear_gpu_memory()\n",
    "print(\"\\n🧹 Final cleanup complete\")\n",
    "print_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Submission Configuration:\n",
      "   Test data: data/test.parquet\n",
      "   Workflow: data/nvt_processed_final/workflow\n",
      "   Submission file: data/submission.csv\n",
      "   Temp test dir: tmp/nvt_processed_test\n"
     ]
    }
   ],
   "source": [
    "# Configuration for submission\n",
    "OUTPUT_DIR = 'data/nvt_processed_final' # Define the output directory path\n",
    "TEST_PATH = 'data/test.parquet'\n",
    "WORKFLOW_PATH = f'{OUTPUT_DIR}/workflow'\n",
    "SUBMISSION_PATH = 'data/submission.csv'\n",
    "TEMP_TEST_DIR = 'tmp/nvt_processed_test' # Processed test data temp dir\n",
    "\n",
    "print(\"📋 Submission Configuration:\")\n",
    "print(f\"   Test data: {TEST_PATH}\")\n",
    "print(f\"   Workflow: {WORKFLOW_PATH}\")\n",
    "print(f\"   Submission file: {SUBMISSION_PATH}\")\n",
    "print(f\"   Temp test dir: {TEMP_TEST_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_ensemble_models(processed_dir, boosting_configs, num_rounds=200):\n",
    "    \"\"\"\n",
    "    Train the final LightGBM ensemble models on the entire processed training dataset.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🚀 Training Final Ensemble Models on Full Data\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # 1. Load full training data\n",
    "    print(\"\\n📦 Loading processed training data...\")\n",
    "    start_load = time.time()\n",
    "    dataset = Dataset(processed_dir, engine='parquet', part_size='256MB')\n",
    "    gdf = dataset.to_ddf().compute()\n",
    "    print(f\"   ✅ Loaded {len(gdf):,} rows in {time.time() - start_load:.1f}s\")\n",
    "    print_memory()\n",
    "\n",
    "    # 2. Prepare data\n",
    "    print(\"\\n📊 Preparing training data...\")\n",
    "    y = gdf['clicked'].to_numpy()\n",
    "    X = gdf.drop('clicked', axis=1)\n",
    "    \n",
    "    # Ensure float32 for LightGBM\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype != 'float32':\n",
    "            X[col] = X[col].astype('float32')\n",
    "    \n",
    "    X_np = X.to_numpy()\n",
    "    train_data = lgb.Dataset(X_np, label=y)\n",
    "    print(\"   ✅ Full training dataset created.\")\n",
    "\n",
    "    del gdf, X\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    # 3. Train ensemble models\n",
    "    print(f\"\\n💪 Training {len(boosting_configs)} models for {num_rounds} rounds...\")\n",
    "    final_models = {}\n",
    "    \n",
    "    for boosting_type, params in boosting_configs.items():\n",
    "        print(f\"\\n🚀 Training {boosting_type.upper()} model...\")\n",
    "        start_train = time.time()\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=num_rounds,\n",
    "            callbacks=[lgb.log_evaluation(50)]  # Show progress every 50 rounds\n",
    "        )\n",
    "        \n",
    "        final_models[boosting_type] = model\n",
    "        print(f\"   ✅ {boosting_type.upper()} model trained in {time.time() - start_train:.1f}s\")\n",
    "    \n",
    "    del train_data\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    return final_models\n",
    "\n",
    "# Use the same parameters from CV\n",
    "pos_ratio = 0.0191  # From CV output, to recalculate scale_pos_weight\n",
    "scale_pos_weight = (1 - pos_ratio) / pos_ratio\n",
    "\n",
    "boosting_configs = {\n",
    "    'gbdt': {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'device_type': 'cpu',\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'scale_pos_weight': scale_pos_weight,\n",
    "        'verbosity': 1,  # Set to 1 to see training progress\n",
    "        'seed': 42,\n",
    "        'num_leaves': 255,\n",
    "        'min_data_in_leaf': 100,\n",
    "        'num_threads': -1,\n",
    "    },\n",
    "    'dart': {\n",
    "        'boosting_type': 'dart',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'device_type': 'cpu',\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'scale_pos_weight': scale_pos_weight,\n",
    "        'verbosity': 1,  # Set to 1 to see training progress\n",
    "        'seed': 42,\n",
    "        'num_leaves': 255,\n",
    "        'min_data_in_leaf': 100,\n",
    "        'drop_rate': 0.1,\n",
    "        'max_drop': 50,\n",
    "        'skip_drop': 0.5,\n",
    "        'num_threads': -1,\n",
    "    },\n",
    "    'goss': {\n",
    "        'boosting_type': 'goss',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'device_type': 'cpu',\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'scale_pos_weight': scale_pos_weight,\n",
    "        'verbosity': 1,  # Set to 1 to see training progress\n",
    "        'seed': 42,\n",
    "        'num_leaves': 255,\n",
    "        'min_data_in_leaf': 100,\n",
    "        'top_rate': 0.2,\n",
    "        'other_rate': 0.1,\n",
    "        'num_threads': -1,\n",
    "    }\n",
    "}\n",
    "\n",
    "# The CV showed that 200 rounds is optimal\n",
    "final_models = train_final_ensemble_models(processed_dir, boosting_configs, num_rounds=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "📄 제출 파일 생성 중 (모든 문제 해결 최종 버전)\n",
      "======================================================================\n",
      "\n",
      "🔍 data/nvt_processed_final/workflow에서 워크플로우 불러오는 중...\n",
      "   ✅ 워크플로우 불러오기 완료.\n",
      "\n",
      "🔧 CPU에서 테스트 데이터 로드 및 정렬 중...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ 정렬된 테스트 데이터 준비 완료.\n",
      "\n",
      "💾 처리된 테스트 데이터 변환 및 저장 중...\n",
      "   ✅ 테스트 데이터 처리 완료.\n",
      "\n",
      "📦 예측을 위해 처리된 테스트 데이터 불러오는 중...\n",
      "   ✅ 1,527,298개 테스트 행 불러오기 완료.\n",
      "\n",
      "🧠 테스트 데이터로 예측 중...\n",
      "   ✅ 예측 완료.\n",
      "\n",
      "✍️ 제출 파일 생성 중...\n",
      "   ✅ 제출 파일 저장 완료: data/submission.csv\n",
      "   미리보기:\n",
      "             ID   clicked\n",
      "0  TEST_0000000  0.623566\n",
      "1  TEST_0000001  0.425492\n",
      "2  TEST_0000002  0.717925\n",
      "3  TEST_0000003  0.417693\n",
      "4  TEST_0000004  0.870040\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cudf\n",
    "import dask.dataframe as dd\n",
    "import lightgbm as lgb\n",
    "import nvtabular as nvt\n",
    "from merlin.io import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import gc\n",
    "import cupy as cp\n",
    "\n",
    "# 노트북의 헬퍼 함수\n",
    "def clear_gpu_memory():\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    gc.collect()\n",
    "\n",
    "def create_submission_ensemble(final_models, workflow_path, test_path, submission_path, temp_dir):\n",
    "    \"\"\"\n",
    "    테스트 데이터를 처리하고, LightGBM 앙상블로 예측하며, 제출 파일을 생성합니다.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"📄 제출 파일 생성 중 (LightGBM 앙상블 최종 버전)\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # 1. 원본 워크플로우 불러오기\n",
    "    print(f\"\\n🔍 {workflow_path}에서 워크플로우 불러오는 중...\")\n",
    "    workflow = nvt.Workflow.load(workflow_path)\n",
    "    print(\"   ✅ 워크플로우 불러오기 완료.\")\n",
    "\n",
    "    # 2. [오류 수정 1] CPU(Pandas)에서 테스트 데이터를 읽고 ID('seq') 기준으로 정렬\n",
    "    print(\"\\n🔧 CPU에서 테스트 데이터 로드 및 정렬 중...\")\n",
    "    test_df = pd.read_parquet(test_path)\n",
    "    test_df = test_df.sort_values('seq').reset_index(drop=True)\n",
    "    \n",
    "    # 워크플로우 통과를 위한 더미 'clicked' 컬럼 추가\n",
    "    test_df['clicked'] = 0\n",
    "    test_df['clicked'] = test_df['clicked'].astype('int8')\n",
    "    \n",
    "    # 정렬된 Pandas DataFrame을 Dataset 객체로 만들어 타입 문제를 해결\n",
    "    test_dataset_sorted = Dataset(test_df, cpu=True)\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    print(\"   ✅ 정렬된 테스트 데이터 준비 완료.\")\n",
    "\n",
    "    # 3. 정렬된 테스트 데이터 처리 (순서 보존)\n",
    "    print(\"\\n💾 처리된 테스트 데이터 변환 및 저장 중...\")\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    workflow.transform(test_dataset_sorted).to_parquet(output_path=temp_dir, shuffle=False)\n",
    "    print(\"   ✅ 테스트 데이터 처리 완료.\")\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    # 4. [오류 수정 2] 안정적인 Dask/Pandas로 처리된 데이터 불러오기\n",
    "    print(\"\\n📦 예측을 위해 처리된 테스트 데이터 불러오는 중...\")\n",
    "    processed_pandas_df = dd.read_parquet(temp_dir).compute()\n",
    "    processed_test_gdf = cudf.DataFrame.from_pandas(processed_pandas_df)\n",
    "    del processed_pandas_df\n",
    "    gc.collect()\n",
    "    print(f\"   ✅ {len(processed_test_gdf):,}개 테스트 행 불러오기 완료.\")\n",
    "\n",
    "    # 더미 'clicked' 컬럼 삭제\n",
    "    feature_cols = [col for col in processed_test_gdf.columns if col != 'clicked']\n",
    "    processed_test_gdf = processed_test_gdf[feature_cols]\n",
    "\n",
    "    # 데이터 타입 변환 및 NumPy 배열 생성 (LightGBM용)\n",
    "    for col in processed_test_gdf.columns:\n",
    "        if processed_test_gdf[col].dtype != 'float32':\n",
    "            processed_test_gdf[col] = processed_test_gdf[col].astype('float32')\n",
    "    \n",
    "    test_X = processed_test_gdf.to_numpy()\n",
    "    del processed_test_gdf\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    # 5. 앙상블 예측 수행\n",
    "    print(f\"\\n🧠 {len(final_models)}개 모델로 앙상블 예측 중...\")\n",
    "    ensemble_predictions = []\n",
    "    \n",
    "    for boosting_type, model in final_models.items():\n",
    "        print(f\"   🔮 {boosting_type.upper()} 모델 예측 중...\")\n",
    "        start_time = time.time()\n",
    "        pred = model.predict(test_X)\n",
    "        ensemble_predictions.append(pred)\n",
    "        print(f\"      ✅ {boosting_type.upper()} 예측 완료 ({time.time() - start_time:.1f}s)\")\n",
    "    \n",
    "    # 앙상블 평균 계산\n",
    "    print(\"   🎯 앙상블 평균 계산 중...\")\n",
    "    final_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "    print(\"   ✅ 앙상블 예측 완료.\")\n",
    "    \n",
    "    del test_X, ensemble_predictions\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    # 6. 제출 파일 생성\n",
    "    print(\"\\n✍️ 제출 파일 생성 중...\")\n",
    "    SAMPLE_SUBMISSION_PATH = 'sample_submission.csv' \n",
    "    sub_df = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n",
    "    sub_df = sub_df.sort_values('ID').reset_index(drop=True)\n",
    "    sub_df['clicked'] = final_predictions\n",
    "    sub_df.to_csv(submission_path, index=False)\n",
    "    print(f\"   ✅ 제출 파일 저장 완료: {submission_path}\")\n",
    "    print(f\"   미리보기:\\n{sub_df.head()}\")\n",
    "    \n",
    "    # 앙상블 통계 정보\n",
    "    print(f\"\\n📊 앙상블 예측 통계:\")\n",
    "    print(f\"   평균: {final_predictions.mean():.6f}\")\n",
    "    print(f\"   표준편차: {final_predictions.std():.6f}\")\n",
    "    print(f\"   최솟값: {final_predictions.min():.6f}\")\n",
    "    print(f\"   최댓값: {final_predictions.max():.6f}\")\n",
    "\n",
    "# 함수 실행\n",
    "try:\n",
    "    create_submission_ensemble(final_models, WORKFLOW_PATH, TEST_PATH, SUBMISSION_PATH, TEMP_TEST_DIR)\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ 예기치 않은 오류가 발생했습니다: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
