{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVIDIA Merlin XGBoost\n",
    "Complete implementation with proper memory management and debugging outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment configured\n"
     ]
    }
   ],
   "source": [
    "# Environment setup\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Environment configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… nvtabular       23.08.00        (required: â‰¥23.08.00)\n",
      "âœ… cudf            23.10.00        (required: â‰¥23.10)\n",
      "âœ… cupy            13.6.0          (required: â‰¥13.6)\n",
      "âœ… xgboost         3.0.5           (required: â‰¥3.0)\n",
      "âœ… dask            2023.9.2        (required: â‰¥2023.9)\n",
      "âœ… pandas          1.5.3           (required: â‰¥1.5)\n",
      "âœ… numpy           1.23.5          (required: â‰¥1.24)\n",
      "âœ… scikit-learn    1.7.2           (required: â‰¥1.7)\n",
      "âœ… psutil          5.9.8           (required: â‰¥5.9)\n",
      "âœ… pyarrow         12.0.1          (required: â‰¥12.0)\n",
      "\n",
      "âœ… All required libraries are installed and compatible!\n"
     ]
    }
   ],
   "source": [
    "# Required libraries and versions\n",
    "required_libs = {\n",
    "    'nvtabular': '23.08.00',\n",
    "    'cudf': '23.10',      # Prefix match\n",
    "    'cupy': '13.6',       # Prefix match  \n",
    "    'xgboost': '3.0',     # Minimum version\n",
    "    'dask': '2023.9',\n",
    "    'pandas': '1.5',\n",
    "    'numpy': '1.24',\n",
    "    'scikit-learn': '1.7',\n",
    "    'psutil': '5.9',      # 5.9.1 works fine (used in working code)\n",
    "    'pyarrow': '12.0'     # 12.0.1 works fine (used in working code)\n",
    "}\n",
    "\n",
    "# Check installed versions\n",
    "import importlib\n",
    "import warnings\n",
    "\n",
    "# Suppress deprecation warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    try:\n",
    "        import pkg_resources\n",
    "    except:\n",
    "        pkg_resources = None\n",
    "\n",
    "missing_libs = []\n",
    "all_good = True\n",
    "\n",
    "for lib, required_version in required_libs.items():\n",
    "    try:\n",
    "        # Map library names for import\n",
    "        import_name = lib\n",
    "        if lib == 'scikit-learn':\n",
    "            import_name = 'sklearn'\n",
    "        \n",
    "        # Check if library is installed\n",
    "        module = importlib.import_module(import_name)\n",
    "        \n",
    "        # Get installed version\n",
    "        try:\n",
    "            if hasattr(module, '__version__'):\n",
    "                installed_version = module.__version__\n",
    "            elif pkg_resources:\n",
    "                installed_version = pkg_resources.get_distribution(lib).version\n",
    "            else:\n",
    "                installed_version = 'unknown'\n",
    "        except:\n",
    "            installed_version = 'unknown'\n",
    "        \n",
    "        # Check version compatibility\n",
    "        req_major = required_version.split('.')[0]\n",
    "        inst_version_parts = installed_version.split('.')\n",
    "        inst_major = inst_version_parts[0] if installed_version != 'unknown' else ''\n",
    "        \n",
    "        # More lenient version check\n",
    "        if installed_version == 'unknown':\n",
    "            print(f\"âš ï¸  {lib:15} {installed_version:15} (required: â‰¥{required_version})\")\n",
    "        elif float(inst_major) >= float(req_major) if inst_major.isdigit() and req_major.isdigit() else installed_version.startswith(required_version[:3]):\n",
    "            print(f\"âœ… {lib:15} {installed_version:15} (required: â‰¥{required_version})\")\n",
    "        else:\n",
    "            print(f\"âš ï¸  {lib:15} {installed_version:15} (required: â‰¥{required_version}) - but should work\")\n",
    "        \n",
    "    except ImportError:\n",
    "        missing_libs.append(lib)\n",
    "        print(f\"âŒ {lib:15} NOT INSTALLED (required: â‰¥{required_version})\")\n",
    "        all_good = False\n",
    "\n",
    "# Report\n",
    "if missing_libs:\n",
    "    print(f\"\\nâŒ Missing libraries: {', '.join(missing_libs)}\")\n",
    "    print(\"Please install them using conda or pip\")\n",
    "elif all_good:\n",
    "    print(\"\\nâœ… All required libraries are installed and compatible!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully\n",
      "NVTabular version: 23.08.00\n",
      "XGBoost version: 3.0.5\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import psutil\n",
    "\n",
    "# GPU libraries\n",
    "import cudf\n",
    "import cupy as cp\n",
    "\n",
    "# NVTabular\n",
    "import nvtabular as nvt\n",
    "from nvtabular import ops\n",
    "from merlin.io import Dataset\n",
    "\n",
    "# ML libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print(\"âœ… All libraries imported successfully\")\n",
    "print(f\"NVTabular version: {nvt.__version__}\")\n",
    "print(f\"XGBoost version: {xgb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Configuration:\n",
      "   Input: data/train.parquet\n",
      "   Output: data/nvt_processed_final\n",
      "   Folds: 5\n",
      "   Force reprocess: False\n"
     ]
    }
   ],
   "source": [
    "# Configuration(DATA PATH)\n",
    "TRAIN_PATH = 'data/train.parquet'\n",
    "OUTPUT_DIR = 'data/nvt_processed_final'\n",
    "TEMP_DIR = '/tmp'\n",
    "N_FOLDS = 5\n",
    "FORCE_REPROCESS = False  # Set to True to reprocess data\n",
    "\n",
    "print(f\"ğŸ“‹ Configuration:\")\n",
    "print(f\"   Input: {TRAIN_PATH}\")\n",
    "print(f\"   Output: {OUTPUT_DIR}\")\n",
    "print(f\"   Folds: {N_FOLDS}\")\n",
    "print(f\"   Force reprocess: {FORCE_REPROCESS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing memory functions:\n",
      "ğŸ’¾ CPU: 9.5GB/251.6GB (5.5%)\n",
      "ğŸ’¾ GPU: 0.6GB/24.0GB\n",
      "ğŸ§¹ GPU memory cleared\n"
     ]
    }
   ],
   "source": [
    "# Memory management functions\n",
    "def print_memory():\n",
    "    \"\"\"Print current memory usage\"\"\"\n",
    "    mem = psutil.virtual_memory()\n",
    "    \n",
    "    try:\n",
    "        import pynvml\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "        gpu_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        gpu_used = gpu_info.used / 1024**3\n",
    "        gpu_total = gpu_info.total / 1024**3\n",
    "    except:\n",
    "        gpu_used = 0\n",
    "        gpu_total = 0\n",
    "    \n",
    "    print(f\"ğŸ’¾ CPU: {mem.used/1024**3:.1f}GB/{mem.total/1024**3:.1f}GB ({mem.percent:.1f}%)\")\n",
    "    print(f\"ğŸ’¾ GPU: {gpu_used:.1f}GB/{gpu_total:.1f}GB\")\n",
    "    return mem.percent\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Clear GPU memory\"\"\"\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    gc.collect()\n",
    "    print(\"ğŸ§¹ GPU memory cleared\")\n",
    "\n",
    "# Test memory functions\n",
    "print(\"Testing memory functions:\")\n",
    "print_memory()\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Metric functions defined\n"
     ]
    }
   ],
   "source": [
    "# Metric functions\n",
    "def calculate_weighted_logloss(y_true, y_pred, eps=1e-15):\n",
    "    \"\"\"Calculate Weighted LogLoss with 50:50 class weights\"\"\"\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "    \n",
    "    mask_0 = (y_true == 0)\n",
    "    mask_1 = (y_true == 1)\n",
    "    \n",
    "    ll_0 = -np.mean(np.log(1 - y_pred[mask_0])) if mask_0.sum() > 0 else 0\n",
    "    ll_1 = -np.mean(np.log(y_pred[mask_1])) if mask_1.sum() > 0 else 0\n",
    "    \n",
    "    return 0.5 * ll_0 + 0.5 * ll_1\n",
    "\n",
    "def calculate_competition_score(y_true, y_pred):\n",
    "    \"\"\"Calculate competition score: 0.5*AP + 0.5*(1/(1+WLL))\"\"\"\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "    wll = calculate_weighted_logloss(y_true, y_pred)\n",
    "    score = 0.5 * ap + 0.5 * (1 / (1 + wll))\n",
    "    return score, ap, wll\n",
    "\n",
    "print(\"âœ… Metric functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”§ Creating XGBoost-optimized workflow...\n",
      "   Categorical: 5 columns\n",
      "   Continuous: 112 columns\n",
      "   Total features: 117\n",
      "   âœ… Workflow created (no normalization for tree models)\n",
      "âœ… Workflow creation tested successfully\n"
     ]
    }
   ],
   "source": [
    "def create_workflow():\n",
    "    \"\"\"Create NVTabular workflow optimized for XGBoost\"\"\"\n",
    "    print(\"\\nğŸ”§ Creating XGBoost-optimized workflow...\")\n",
    "    \n",
    "    # TRUE CATEGORICAL COLUMNS (only 5)\n",
    "    true_categorical = ['gender', 'age_group', 'inventory_id', 'day_of_week', 'hour']\n",
    "    \n",
    "    # CONTINUOUS COLUMNS (112 total)\n",
    "    all_continuous = (\n",
    "        [f'feat_a_{i}' for i in range(1, 19)] +  # 18\n",
    "        [f'feat_b_{i}' for i in range(1, 7)] +   # 6\n",
    "        [f'feat_c_{i}' for i in range(1, 9)] +   # 8\n",
    "        [f'feat_d_{i}' for i in range(1, 7)] +   # 6\n",
    "        [f'feat_e_{i}' for i in range(1, 11)] +  # 10\n",
    "        [f'history_a_{i}' for i in range(1, 8)] +  # 7\n",
    "        [f'history_b_{i}' for i in range(1, 31)] + # 30\n",
    "        [f'l_feat_{i}' for i in range(1, 28)]      # 27\n",
    "    )\n",
    "    \n",
    "    print(f\"   Categorical: {len(true_categorical)} columns\")\n",
    "    print(f\"   Continuous: {len(all_continuous)} columns\")\n",
    "    print(f\"   Total features: {len(true_categorical) + len(all_continuous)}\")\n",
    "    \n",
    "    # Minimal preprocessing for XGBoost\n",
    "    cat_features = true_categorical >> ops.Categorify(\n",
    "        freq_threshold=0,\n",
    "        max_size=50000\n",
    "    )\n",
    "    cont_features = all_continuous >> ops.FillMissing(fill_val=0)\n",
    "    \n",
    "    workflow = nvt.Workflow(cat_features + cont_features + ['clicked'])\n",
    "    \n",
    "    print(\"   âœ… Workflow created (no normalization for tree models)\")\n",
    "    return workflow\n",
    "\n",
    "# Test workflow creation\n",
    "test_workflow = create_workflow()\n",
    "print(\"âœ… Workflow creation tested successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸš€ NVTabular Data Processing\n",
      "======================================================================\n",
      "âœ… Using existing processed data from data/nvt_processed_final\n"
     ]
    }
   ],
   "source": [
    "def process_data():\n",
    "    \"\"\"Process data with NVTabular\"\"\"\n",
    "    import shutil\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸš€ NVTabular Data Processing\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Check if already processed\n",
    "    if os.path.exists(OUTPUT_DIR) and not FORCE_REPROCESS:\n",
    "        try:\n",
    "            test_dataset = Dataset(OUTPUT_DIR, engine='parquet')\n",
    "            print(f\"âœ… Using existing processed data from {OUTPUT_DIR}\")\n",
    "            return OUTPUT_DIR\n",
    "        except:\n",
    "            print(f\"âš ï¸ Existing data corrupted, reprocessing...\")\n",
    "            shutil.rmtree(OUTPUT_DIR)\n",
    "    \n",
    "    # Clear existing if needed\n",
    "    if os.path.exists(OUTPUT_DIR):\n",
    "        print(f\"ğŸ—‘ï¸ Removing existing directory {OUTPUT_DIR}\")\n",
    "        shutil.rmtree(OUTPUT_DIR)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    initial_mem = print_memory()\n",
    "    \n",
    "    # Prepare data without 'seq' column\n",
    "    temp_path = f'{TEMP_DIR}/train_no_seq.parquet'\n",
    "    if not os.path.exists(temp_path):\n",
    "        print(\"\\nğŸ“‹ Creating temp file without 'seq' column...\")\n",
    "        pf = pq.ParquetFile(TRAIN_PATH)\n",
    "        cols = [c for c in pf.schema.names if c != 'seq']\n",
    "        print(f\"   Total columns: {len(pf.schema.names)}\")\n",
    "        print(f\"   Using columns: {len(cols)} (excluded 'seq')\")\n",
    "        \n",
    "        df = pd.read_parquet(TRAIN_PATH, columns=cols)\n",
    "        print(f\"   Loaded {len(df):,} rows\")\n",
    "        df.to_parquet(temp_path, index=False)\n",
    "        del df\n",
    "        gc.collect()\n",
    "        print(\"   âœ… Temp file created\")\n",
    "    else:\n",
    "        print(f\"âœ… Using existing temp file: {temp_path}\")\n",
    "    \n",
    "    # Create dataset with small partitions\n",
    "    print(\"\\nğŸ“¦ Creating NVTabular Dataset...\")\n",
    "    print(\"   Using 32MB partitions for memory efficiency\")\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    dataset = Dataset(\n",
    "        temp_path,\n",
    "        engine='parquet',\n",
    "        part_size='32MB'  #change size based on your environment\n",
    "    )\n",
    "    print(\"   âœ… Dataset created\")\n",
    "    \n",
    "    # Create and fit workflow\n",
    "    print(\"\\nğŸ“Š Fitting workflow...\")\n",
    "    workflow = create_workflow()\n",
    "    workflow.fit(dataset)\n",
    "    print(\"   âœ… Workflow fitted\")\n",
    "    \n",
    "    # Transform and save\n",
    "    print(f\"\\nğŸ’¾ Transforming and saving to {OUTPUT_DIR}...\")\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    try:\n",
    "        workflow.transform(dataset).to_parquet(\n",
    "            output_path=OUTPUT_DIR,\n",
    "            shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "            out_files_per_proc=8\n",
    "        )\n",
    "        \n",
    "        workflow_path = f'{OUTPUT_DIR}/workflow'\n",
    "        workflow.save(workflow_path)\n",
    "        print(f\"   âœ… Data processed and saved\")\n",
    "        print(f\"   âœ… Workflow saved to {workflow_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during processing: {e}\")\n",
    "        if os.path.exists(OUTPUT_DIR):\n",
    "            shutil.rmtree(OUTPUT_DIR)\n",
    "        raise\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    final_mem = print_memory()\n",
    "    \n",
    "    print(f\"\\nâœ… Processing complete!\")\n",
    "    print(f\"   Time: {elapsed:.1f}s\")\n",
    "    print(f\"   Memory increase: +{final_mem - initial_mem:.1f}%\")\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    return OUTPUT_DIR\n",
    "\n",
    "# Process data\n",
    "processed_dir = process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM ensemble cross-validation...\n",
      "\n",
      "======================================================================\n",
      "ğŸ”„ LightGBM Boosting Type Ensemble Cross-Validation\n",
      "======================================================================\n",
      "\n",
      "ğŸ“¦ Loading processed data...\n",
      "   Converting to GPU DataFrame...\n",
      "   âœ… Loaded 10,704,179 rows x 118 columns\n",
      "   Time: 1.8s\n",
      "ğŸ’¾ CPU: 19.5GB/251.6GB (9.5%)\n",
      "ğŸ’¾ GPU: 5.8GB/24.0GB\n",
      "\n",
      "ğŸ“Š Preparing data for LightGBM...\n",
      "   Shape: (10704179, 117)\n",
      "   Features: 117\n",
      "   Samples: 10,704,179\n",
      "\n",
      "ğŸ“Š Class distribution:\n",
      "   Positive ratio: 0.0191\n",
      "   Scale pos weight: 51.43\n",
      "\n",
      "ğŸ”„ Starting cross-validation...\n",
      "\n",
      "ğŸ“ Fold 1/5\n",
      "   Train: 8,563,343 | Val: 2,140,836\n",
      "   ğŸš€ Training GBDT...\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "\n",
    "def run_cv_lgbm_ensemble(processed_dir, n_folds=5): \n",
    "    \"\"\"Run stratified cross-validation with LightGBM ensemble of different boosting types\"\"\" \n",
    "    print(\"\\n\" + \"=\"*70) \n",
    "    print(\"ğŸ”„ LightGBM Boosting Type Ensemble Cross-Validation\") \n",
    "    print(\"=\"*70) \n",
    "     \n",
    "    # Load processed data \n",
    "    print(\"\\nğŸ“¦ Loading processed data...\") \n",
    "    start_load = time.time() \n",
    "     \n",
    "    try: \n",
    "        dataset = Dataset(processed_dir, engine='parquet', part_size='256MB') \n",
    "        print(\"   Converting to GPU DataFrame...\") \n",
    "        gdf = dataset.to_ddf().compute() \n",
    "        print(f\"   âœ… Loaded {len(gdf):,} rows x {len(gdf.columns)} columns\") \n",
    "        print(f\"   Time: {time.time() - start_load:.1f}s\") \n",
    "    except Exception as e: \n",
    "        print(f\"âŒ Error loading data: {e}\") \n",
    "        return None \n",
    "     \n",
    "    print_memory() \n",
    "     \n",
    "    # Prepare data \n",
    "    print(\"\\nğŸ“Š Preparing data for LightGBM...\") \n",
    "    y = gdf['clicked'].to_numpy() \n",
    "    X = gdf.drop('clicked', axis=1) \n",
    "     \n",
    "    # Convert to float32 \n",
    "    for col in X.columns: \n",
    "        if X[col].dtype != 'float32': \n",
    "            X[col] = X[col].astype('float32') \n",
    "     \n",
    "    X_np = X.to_numpy() \n",
    "    print(f\"   Shape: {X_np.shape}\") \n",
    "    print(f\"   Features: {X.shape[1]}\") \n",
    "    print(f\"   Samples: {X.shape[0]:,}\") \n",
    "     \n",
    "    # Class distribution \n",
    "    pos_ratio = y.mean() \n",
    "    scale_pos_weight = (1 - pos_ratio) / pos_ratio \n",
    "    print(f\"\\nğŸ“Š Class distribution:\") \n",
    "    print(f\"   Positive ratio: {pos_ratio:.4f}\") \n",
    "    print(f\"   Scale pos weight: {scale_pos_weight:.2f}\") \n",
    "     \n",
    "    del X, gdf \n",
    "    clear_gpu_memory() \n",
    "     \n",
    "    # Define different boosting types and their parameters\n",
    "    boosting_configs = {\n",
    "        'gbdt': {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'device_type': 'cpu',\n",
    "            'max_depth': 8,\n",
    "            'learning_rate': 0.1,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'scale_pos_weight': scale_pos_weight,\n",
    "            'verbose': -1,\n",
    "            'seed': 42,\n",
    "            'num_leaves': 255,\n",
    "            'min_data_in_leaf': 100,\n",
    "        },\n",
    "        'dart': {\n",
    "            'boosting_type': 'dart',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'device_type': 'cpu',\n",
    "            'max_depth': 8,\n",
    "            'learning_rate': 0.1,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'scale_pos_weight': scale_pos_weight,\n",
    "            'verbose': -1,\n",
    "            'seed': 42,\n",
    "            'num_leaves': 255,\n",
    "            'min_data_in_leaf': 100,\n",
    "            'drop_rate': 0.1,\n",
    "            'max_drop': 50,\n",
    "            'skip_drop': 0.5,\n",
    "        },\n",
    "        'goss': {\n",
    "            'boosting_type': 'goss',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'device_type': 'cpu',\n",
    "            'max_depth': 8,\n",
    "            'learning_rate': 0.1,\n",
    "            'feature_fraction': 0.8,\n",
    "            'scale_pos_weight': scale_pos_weight,\n",
    "            'verbose': -1,\n",
    "            'seed': 42,\n",
    "            'num_leaves': 255,\n",
    "            'min_data_in_leaf': 100,\n",
    "            'top_rate': 0.2,\n",
    "            'other_rate': 0.1,\n",
    "        }\n",
    "    }\n",
    "     \n",
    "    # Cross-validation \n",
    "    print(\"\\nğŸ”„ Starting cross-validation...\") \n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42) \n",
    "     \n",
    "    # Store results for each boosting type\n",
    "    all_results = {boosting_type: {'scores': [], 'ap': [], 'wll': [], 'predictions': []} \n",
    "                   for boosting_type in boosting_configs.keys()}\n",
    "    ensemble_results = {'scores': [], 'ap': [], 'wll': []}\n",
    "     \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_np, y), 1): \n",
    "        print(f\"\\nğŸ“ Fold {fold}/{n_folds}\") \n",
    "        fold_start = time.time() \n",
    "         \n",
    "        print(f\"   Train: {len(train_idx):,} | Val: {len(val_idx):,}\") \n",
    "        \n",
    "        # Create LightGBM datasets\n",
    "        train_data = lgb.Dataset(X_np[train_idx], label=y[train_idx])\n",
    "        val_data = lgb.Dataset(X_np[val_idx], label=y[val_idx], reference=train_data)\n",
    "        \n",
    "        fold_predictions = {}\n",
    "        \n",
    "        # Train each boosting type\n",
    "        for boosting_type, params in boosting_configs.items():\n",
    "            print(f\"   ğŸš€ Training {boosting_type.upper()}...\")\n",
    "            boosting_start = time.time()\n",
    "            \n",
    "            # Train model\n",
    "            model = lgb.train(\n",
    "                params,\n",
    "                train_data,\n",
    "                num_boost_round=200,\n",
    "                valid_sets=[val_data],\n",
    "                callbacks=[\n",
    "                    lgb.early_stopping(20, verbose=False),\n",
    "                    lgb.log_evaluation(0)  # No verbose output\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Predict\n",
    "            y_pred = model.predict(X_np[val_idx], num_iteration=model.best_iteration)\n",
    "            fold_predictions[boosting_type] = y_pred\n",
    "            \n",
    "            # Evaluate individual model\n",
    "            score, ap, wll = calculate_competition_score(y[val_idx], y_pred)\n",
    "            \n",
    "            all_results[boosting_type]['scores'].append(score)\n",
    "            all_results[boosting_type]['ap'].append(ap)\n",
    "            all_results[boosting_type]['wll'].append(wll)\n",
    "            all_results[boosting_type]['predictions'].append(y_pred)\n",
    "            \n",
    "            print(f\"      {boosting_type.upper()} - Score: {score:.6f}, AP: {ap:.6f}, WLL: {wll:.6f}\")\n",
    "            print(f\"      Best iteration: {model.best_iteration}, Time: {time.time() - boosting_start:.1f}s\")\n",
    "            \n",
    "            del model\n",
    "            clear_gpu_memory()\n",
    "        \n",
    "        # Create ensemble prediction (simple average)\n",
    "        print(\"   ğŸ¯ Creating ensemble...\")\n",
    "        ensemble_pred = np.mean([fold_predictions[bt] for bt in boosting_configs.keys()], axis=0)\n",
    "        \n",
    "        # Evaluate ensemble\n",
    "        ensemble_score, ensemble_ap, ensemble_wll = calculate_competition_score(y[val_idx], ensemble_pred)\n",
    "        \n",
    "        ensemble_results['scores'].append(ensemble_score)\n",
    "        ensemble_results['ap'].append(ensemble_ap)\n",
    "        ensemble_results['wll'].append(ensemble_wll)\n",
    "        \n",
    "        print(f\"   ğŸ† ENSEMBLE - Score: {ensemble_score:.6f}, AP: {ensemble_ap:.6f}, WLL: {ensemble_wll:.6f}\")\n",
    "        print(f\"   â±ï¸ Total fold time: {time.time() - fold_start:.1f}s\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del train_data, val_data\n",
    "        clear_gpu_memory()\n",
    "     \n",
    "    # Final results \n",
    "    print(\"\\n\" + \"=\"*80) \n",
    "    print(\"ğŸ“Š Final Cross-Validation Results\") \n",
    "    print(\"=\"*80) \n",
    "    \n",
    "    # Individual boosting type results\n",
    "    print(\"\\nğŸ“ˆ Individual Boosting Type Results:\")\n",
    "    for boosting_type in boosting_configs.keys():\n",
    "        results = all_results[boosting_type]\n",
    "        mean_score = np.mean(results['scores'])\n",
    "        std_score = np.std(results['scores'])\n",
    "        mean_ap = np.mean(results['ap'])\n",
    "        std_ap = np.std(results['ap'])\n",
    "        mean_wll = np.mean(results['wll'])\n",
    "        std_wll = np.std(results['wll'])\n",
    "        \n",
    "        print(f\"\\nğŸ”¹ {boosting_type.upper()}:\")\n",
    "        print(f\"   Competition Score: {mean_score:.6f} Â± {std_score:.6f}\")\n",
    "        print(f\"   Average Precision: {mean_ap:.6f} Â± {std_ap:.6f}\")\n",
    "        print(f\"   Weighted LogLoss:  {mean_wll:.6f} Â± {std_wll:.6f}\")\n",
    "        print(f\"   All scores: {[f'{s:.6f}' for s in results['scores']]}\")\n",
    "    \n",
    "    # Ensemble results\n",
    "    print(f\"\\nğŸ† ENSEMBLE RESULTS:\")\n",
    "    print(f\"   Competition Score: {np.mean(ensemble_results['scores']):.6f} Â± {np.std(ensemble_results['scores']):.6f}\")\n",
    "    print(f\"   Average Precision: {np.mean(ensemble_results['ap']):.6f} Â± {np.std(ensemble_results['ap']):.6f}\")\n",
    "    print(f\"   Weighted LogLoss:  {np.mean(ensemble_results['wll']):.6f} Â± {np.std(ensemble_results['wll']):.6f}\")\n",
    "    print(f\"   All scores: {[f'{s:.6f}' for s in ensemble_results['scores']]}\")\n",
    "    \n",
    "    # Performance comparison\n",
    "    print(f\"\\nğŸ“Š Performance Summary:\")\n",
    "    best_individual = max(boosting_configs.keys(), \n",
    "                         key=lambda bt: np.mean(all_results[bt]['scores']))\n",
    "    best_individual_score = np.mean(all_results[best_individual]['scores'])\n",
    "    ensemble_score = np.mean(ensemble_results['scores'])\n",
    "    \n",
    "    print(f\"   Best individual: {best_individual.upper()} ({best_individual_score:.6f})\")\n",
    "    print(f\"   Ensemble score: {ensemble_score:.6f}\")\n",
    "    print(f\"   Improvement: {ensemble_score - best_individual_score:+.6f}\")\n",
    "    \n",
    "    return ensemble_results, all_results\n",
    "\n",
    "def train_final_ensemble_models(processed_dir, boosting_configs):\n",
    "    \"\"\"Train final ensemble models on full dataset\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ¯ Training Final Ensemble Models\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load data (same as before)\n",
    "    dataset = Dataset(processed_dir, engine='parquet', part_size='256MB')\n",
    "    gdf = dataset.to_ddf().compute()\n",
    "    \n",
    "    y = gdf['clicked'].to_numpy()\n",
    "    X = gdf.drop('clicked', axis=1)\n",
    "    \n",
    "    for col in X.columns:\n",
    "        if X[col].dtype != 'float32':\n",
    "            X[col] = X[col].astype('float32')\n",
    "    \n",
    "    X_np = X.to_numpy()\n",
    "    del X, gdf\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    # Train final models\n",
    "    final_models = {}\n",
    "    train_data = lgb.Dataset(X_np, label=y)\n",
    "    \n",
    "    for boosting_type, params in boosting_configs.items():\n",
    "        print(f\"\\nğŸš€ Training final {boosting_type.upper()} model...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=200,\n",
    "            callbacks=[lgb.log_evaluation(0)]\n",
    "        )\n",
    "        \n",
    "        final_models[boosting_type] = model\n",
    "        print(f\"   âœ… Completed in {time.time() - start_time:.1f}s\")\n",
    "    \n",
    "    return final_models\n",
    "\n",
    "# Run cross-validation with ensemble\n",
    "print(\"Starting LightGBM ensemble cross-validation...\")\n",
    "ensemble_results, individual_results = run_cv_lgbm_ensemble(processed_dir, N_FOLDS)\n",
    "\n",
    "# Train final models for inference\n",
    "boosting_configs = {\n",
    "    'gbdt': {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'device_type': 'cpu',\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': 42,\n",
    "        'num_leaves': 255,\n",
    "        'min_data_in_leaf': 100,\n",
    "    },\n",
    "    'dart': {\n",
    "        'boosting_type': 'dart',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'device_type': 'cpu',\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': 42,\n",
    "        'num_leaves': 255,\n",
    "        'min_data_in_leaf': 100,\n",
    "        'drop_rate': 0.1,\n",
    "        'max_drop': 50,\n",
    "        'skip_drop': 0.5,\n",
    "    },\n",
    "    'goss': {\n",
    "        'boosting_type': 'goss',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'device_type': 'cpu',\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'verbose': -1,\n",
    "        'seed': 42,\n",
    "        'num_leaves': 255,\n",
    "        'min_data_in_leaf': 100,\n",
    "        'top_rate': 0.2,\n",
    "        'other_rate': 0.1,\n",
    "    }\n",
    "}\n",
    "\n",
    "final_models = train_final_ensemble_models(processed_dir, boosting_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰\n",
      "COMPLETE!\n",
      "ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰\n",
      "\n",
      "âœ… Final CV Score: 0.353147 Â± 0.000375\n",
      "âœ… Full dataset processed (10.7M rows)\n",
      "âœ… XGBoost-optimized preprocessing (no normalization)\n",
      "âœ… Memory-efficient with small partitions\n",
      "======================================================================\n",
      "ğŸ§¹ GPU memory cleared\n",
      "\n",
      "ğŸ§¹ Final cleanup complete\n",
      "ğŸ’¾ CPU: 9.7GB/251.6GB (5.6%)\n",
      "ğŸ’¾ GPU: 0.6GB/24.0GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ensemble_results:\n",
    "    cv_scores = ensemble_results['scores']\n",
    "    print(\"\\n\" + \"ğŸ‰\"*35)\n",
    "    print(\"COMPLETE!\")\n",
    "    print(\"ğŸ‰\"*35)\n",
    "    print(f\"\\nâœ… Final CV Score: {np.mean(cv_scores):.6f} Â± {np.std(cv_scores):.6f}\")\n",
    "    print(\"âœ… Full dataset processed (10.7M rows)\")\n",
    "    print(\"âœ… LightGBM-ensemble preprocessing (GBDT+DART+GOSS)\")\n",
    "    print(\"âœ… Memory-efficient with small partitions\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Cross-validation did not complete. Please check for errors above.\")\n",
    "\n",
    "# Final cleanup\n",
    "clear_gpu_memory()\n",
    "print(\"\\nğŸ§¹ Final cleanup complete\")\n",
    "print_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Submission Configuration:\n",
      "   Test data: data/test.parquet\n",
      "   Workflow: data/nvt_processed_final/workflow\n",
      "   Submission file: data/submission.csv\n",
      "   Temp test dir: tmp/nvt_processed_test\n"
     ]
    }
   ],
   "source": [
    "# Configuration for submission\n",
    "OUTPUT_DIR = 'data/nvt_processed_final' # Define the output directory path\n",
    "TEST_PATH = 'data/test.parquet'\n",
    "WORKFLOW_PATH = f'{OUTPUT_DIR}/workflow'\n",
    "SUBMISSION_PATH = 'data/submission.csv'\n",
    "TEMP_TEST_DIR = 'tmp/nvt_processed_test' # Processed test data temp dir\n",
    "\n",
    "print(\"ğŸ“‹ Submission Configuration:\")\n",
    "print(f\"   Test data: {TEST_PATH}\")\n",
    "print(f\"   Workflow: {WORKFLOW_PATH}\")\n",
    "print(f\"   Submission file: {SUBMISSION_PATH}\")\n",
    "print(f\"   Temp test dir: {TEMP_TEST_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_ensemble_models(processed_dir, boosting_configs, num_rounds=200):\n",
    "    \"\"\"\n",
    "    Train the final LightGBM ensemble models on the entire processed training dataset.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸš€ Training Final Ensemble Models on Full Data\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # 1. Load full training data\n",
    "    print(\"\\nğŸ“¦ Loading processed training data...\")\n",
    "    start_load = time.time()\n",
    "    dataset = Dataset(processed_dir, engine='parquet', part_size='256MB')\n",
    "    gdf = dataset.to_ddf().compute()\n",
    "    print(f\"   âœ… Loaded {len(gdf):,} rows in {time.time() - start_load:.1f}s\")\n",
    "    print_memory()\n",
    "\n",
    "    # 2. Prepare data\n",
    "    print(\"\\nğŸ“Š Preparing training data...\")\n",
    "    y = gdf['clicked'].to_numpy()\n",
    "    X = gdf.drop('clicked', axis=1)\n",
    "    \n",
    "    # Ensure float32 for LightGBM\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype != 'float32':\n",
    "            X[col] = X[col].astype('float32')\n",
    "    \n",
    "    X_np = X.to_numpy()\n",
    "    train_data = lgb.Dataset(X_np, label=y)\n",
    "    print(\"   âœ… Full training dataset created.\")\n",
    "\n",
    "    del gdf, X\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    # 3. Train ensemble models\n",
    "    print(f\"\\nğŸ’ª Training {len(boosting_configs)} models for {num_rounds} rounds...\")\n",
    "    final_models = {}\n",
    "    \n",
    "    for boosting_type, params in boosting_configs.items():\n",
    "        print(f\"\\nğŸš€ Training {boosting_type.upper()} model...\")\n",
    "        start_train = time.time()\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=num_rounds,\n",
    "            callbacks=[lgb.log_evaluation(50)]  # Show progress every 50 rounds\n",
    "        )\n",
    "        \n",
    "        final_models[boosting_type] = model\n",
    "        print(f\"   âœ… {boosting_type.upper()} model trained in {time.time() - start_train:.1f}s\")\n",
    "    \n",
    "    del train_data\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    return final_models\n",
    "\n",
    "# Use the same parameters from CV\n",
    "pos_ratio = 0.0191  # From CV output, to recalculate scale_pos_weight\n",
    "scale_pos_weight = (1 - pos_ratio) / pos_ratio\n",
    "\n",
    "boosting_configs = {\n",
    "    'gbdt': {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'device_type': 'cpu',\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'scale_pos_weight': scale_pos_weight,\n",
    "        'verbosity': 1,  # Set to 1 to see training progress\n",
    "        'seed': 42,\n",
    "        'num_leaves': 255,\n",
    "        'min_data_in_leaf': 100,\n",
    "        'num_threads': -1,\n",
    "    },\n",
    "    'dart': {\n",
    "        'boosting_type': 'dart',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'device_type': 'cpu',\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'scale_pos_weight': scale_pos_weight,\n",
    "        'verbosity': 1,  # Set to 1 to see training progress\n",
    "        'seed': 42,\n",
    "        'num_leaves': 255,\n",
    "        'min_data_in_leaf': 100,\n",
    "        'drop_rate': 0.1,\n",
    "        'max_drop': 50,\n",
    "        'skip_drop': 0.5,\n",
    "        'num_threads': -1,\n",
    "    },\n",
    "    'goss': {\n",
    "        'boosting_type': 'goss',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'device_type': 'cpu',\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'scale_pos_weight': scale_pos_weight,\n",
    "        'verbosity': 1,  # Set to 1 to see training progress\n",
    "        'seed': 42,\n",
    "        'num_leaves': 255,\n",
    "        'min_data_in_leaf': 100,\n",
    "        'top_rate': 0.2,\n",
    "        'other_rate': 0.1,\n",
    "        'num_threads': -1,\n",
    "    }\n",
    "}\n",
    "\n",
    "# The CV showed that 200 rounds is optimal\n",
    "final_models = train_final_ensemble_models(processed_dir, boosting_configs, num_rounds=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“„ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘ (ëª¨ë“  ë¬¸ì œ í•´ê²° ìµœì¢… ë²„ì „)\n",
      "======================================================================\n",
      "\n",
      "ğŸ” data/nvt_processed_final/workflowì—ì„œ ì›Œí¬í”Œë¡œìš° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\n",
      "   âœ… ì›Œí¬í”Œë¡œìš° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ.\n",
      "\n",
      "ğŸ”§ CPUì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ë° ì •ë ¬ ì¤‘...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… ì •ë ¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ.\n",
      "\n",
      "ğŸ’¾ ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³€í™˜ ë° ì €ì¥ ì¤‘...\n",
      "   âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ.\n",
      "\n",
      "ğŸ“¦ ì˜ˆì¸¡ì„ ìœ„í•´ ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\n",
      "   âœ… 1,527,298ê°œ í…ŒìŠ¤íŠ¸ í–‰ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ.\n",
      "\n",
      "ğŸ§  í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ì¤‘...\n",
      "   âœ… ì˜ˆì¸¡ ì™„ë£Œ.\n",
      "\n",
      "âœï¸ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...\n",
      "   âœ… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: data/submission.csv\n",
      "   ë¯¸ë¦¬ë³´ê¸°:\n",
      "             ID   clicked\n",
      "0  TEST_0000000  0.623566\n",
      "1  TEST_0000001  0.425492\n",
      "2  TEST_0000002  0.717925\n",
      "3  TEST_0000003  0.417693\n",
      "4  TEST_0000004  0.870040\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cudf\n",
    "import dask.dataframe as dd\n",
    "import lightgbm as lgb\n",
    "import nvtabular as nvt\n",
    "from merlin.io import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import gc\n",
    "import cupy as cp\n",
    "\n",
    "# ë…¸íŠ¸ë¶ì˜ í—¬í¼ í•¨ìˆ˜\n",
    "def clear_gpu_memory():\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    gc.collect()\n",
    "\n",
    "def create_submission_ensemble(final_models, workflow_path, test_path, submission_path, temp_dir):\n",
    "    \"\"\"\n",
    "    í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³ , LightGBM ì•™ìƒë¸”ë¡œ ì˜ˆì¸¡í•˜ë©°, ì œì¶œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“„ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘ (LightGBM ì•™ìƒë¸” ìµœì¢… ë²„ì „)\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # 1. ì›ë³¸ ì›Œí¬í”Œë¡œìš° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    print(f\"\\nğŸ” {workflow_path}ì—ì„œ ì›Œí¬í”Œë¡œìš° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\")\n",
    "    workflow = nvt.Workflow.load(workflow_path)\n",
    "    print(\"   âœ… ì›Œí¬í”Œë¡œìš° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ.\")\n",
    "\n",
    "    # 2. [ì˜¤ë¥˜ ìˆ˜ì • 1] CPU(Pandas)ì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì½ê³  ID('seq') ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
    "    print(\"\\nğŸ”§ CPUì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ë° ì •ë ¬ ì¤‘...\")\n",
    "    test_df = pd.read_parquet(test_path)\n",
    "    test_df = test_df.sort_values('seq').reset_index(drop=True)\n",
    "    \n",
    "    # ì›Œí¬í”Œë¡œìš° í†µê³¼ë¥¼ ìœ„í•œ ë”ë¯¸ 'clicked' ì»¬ëŸ¼ ì¶”ê°€\n",
    "    test_df['clicked'] = 0\n",
    "    test_df['clicked'] = test_df['clicked'].astype('int8')\n",
    "    \n",
    "    # ì •ë ¬ëœ Pandas DataFrameì„ Dataset ê°ì²´ë¡œ ë§Œë“¤ì–´ íƒ€ì… ë¬¸ì œë¥¼ í•´ê²°\n",
    "    test_dataset_sorted = Dataset(test_df, cpu=True)\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    print(\"   âœ… ì •ë ¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ.\")\n",
    "\n",
    "    # 3. ì •ë ¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬ (ìˆœì„œ ë³´ì¡´)\n",
    "    print(\"\\nğŸ’¾ ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³€í™˜ ë° ì €ì¥ ì¤‘...\")\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    workflow.transform(test_dataset_sorted).to_parquet(output_path=temp_dir, shuffle=False)\n",
    "    print(\"   âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ.\")\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    # 4. [ì˜¤ë¥˜ ìˆ˜ì • 2] ì•ˆì •ì ì¸ Dask/Pandasë¡œ ì²˜ë¦¬ëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    print(\"\\nğŸ“¦ ì˜ˆì¸¡ì„ ìœ„í•´ ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\")\n",
    "    processed_pandas_df = dd.read_parquet(temp_dir).compute()\n",
    "    processed_test_gdf = cudf.DataFrame.from_pandas(processed_pandas_df)\n",
    "    del processed_pandas_df\n",
    "    gc.collect()\n",
    "    print(f\"   âœ… {len(processed_test_gdf):,}ê°œ í…ŒìŠ¤íŠ¸ í–‰ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ.\")\n",
    "\n",
    "    # ë”ë¯¸ 'clicked' ì»¬ëŸ¼ ì‚­ì œ\n",
    "    feature_cols = [col for col in processed_test_gdf.columns if col != 'clicked']\n",
    "    processed_test_gdf = processed_test_gdf[feature_cols]\n",
    "\n",
    "    # ë°ì´í„° íƒ€ì… ë³€í™˜ ë° NumPy ë°°ì—´ ìƒì„± (LightGBMìš©)\n",
    "    for col in processed_test_gdf.columns:\n",
    "        if processed_test_gdf[col].dtype != 'float32':\n",
    "            processed_test_gdf[col] = processed_test_gdf[col].astype('float32')\n",
    "    \n",
    "    test_X = processed_test_gdf.to_numpy()\n",
    "    del processed_test_gdf\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    # 5. ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    print(f\"\\nğŸ§  {len(final_models)}ê°œ ëª¨ë¸ë¡œ ì•™ìƒë¸” ì˜ˆì¸¡ ì¤‘...\")\n",
    "    ensemble_predictions = []\n",
    "    \n",
    "    for boosting_type, model in final_models.items():\n",
    "        print(f\"   ğŸ”® {boosting_type.upper()} ëª¨ë¸ ì˜ˆì¸¡ ì¤‘...\")\n",
    "        start_time = time.time()\n",
    "        pred = model.predict(test_X)\n",
    "        ensemble_predictions.append(pred)\n",
    "        print(f\"      âœ… {boosting_type.upper()} ì˜ˆì¸¡ ì™„ë£Œ ({time.time() - start_time:.1f}s)\")\n",
    "    \n",
    "    # ì•™ìƒë¸” í‰ê·  ê³„ì‚°\n",
    "    print(\"   ğŸ¯ ì•™ìƒë¸” í‰ê·  ê³„ì‚° ì¤‘...\")\n",
    "    final_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "    print(\"   âœ… ì•™ìƒë¸” ì˜ˆì¸¡ ì™„ë£Œ.\")\n",
    "    \n",
    "    del test_X, ensemble_predictions\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    # 6. ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "    print(\"\\nâœï¸ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...\")\n",
    "    SAMPLE_SUBMISSION_PATH = 'sample_submission.csv' \n",
    "    sub_df = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n",
    "    sub_df = sub_df.sort_values('ID').reset_index(drop=True)\n",
    "    sub_df['clicked'] = final_predictions\n",
    "    sub_df.to_csv(submission_path, index=False)\n",
    "    print(f\"   âœ… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {submission_path}\")\n",
    "    print(f\"   ë¯¸ë¦¬ë³´ê¸°:\\n{sub_df.head()}\")\n",
    "    \n",
    "    # ì•™ìƒë¸” í†µê³„ ì •ë³´\n",
    "    print(f\"\\nğŸ“Š ì•™ìƒë¸” ì˜ˆì¸¡ í†µê³„:\")\n",
    "    print(f\"   í‰ê· : {final_predictions.mean():.6f}\")\n",
    "    print(f\"   í‘œì¤€í¸ì°¨: {final_predictions.std():.6f}\")\n",
    "    print(f\"   ìµœì†Ÿê°’: {final_predictions.min():.6f}\")\n",
    "    print(f\"   ìµœëŒ“ê°’: {final_predictions.max():.6f}\")\n",
    "\n",
    "# í•¨ìˆ˜ ì‹¤í–‰\n",
    "try:\n",
    "    create_submission_ensemble(final_models, WORKFLOW_PATH, TEST_PATH, SUBMISSION_PATH, TEMP_TEST_DIR)\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
