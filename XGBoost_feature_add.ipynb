{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09a72361",
   "metadata": {},
   "source": [
    "## Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f168817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pyarrow.dataset as ds\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a7780",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d39ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Settings\n",
    "CFG = {\n",
    "    'BATCH_SIZE': 800_000,\n",
    "    'NUM_BOOST_ROUND': 2000,\n",
    "    'LEARNING_RATE': 0.05,\n",
    "    'SEED': 42,\n",
    "    'TEST_SIZE': 0.2,\n",
    "    'EARLY_STOPPING': 100,\n",
    "    'N_FOLDS': 5,\n",
    "    'OPTUNA_TRIALS': 20\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b31fa5",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d8acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_seq_features(seq_str):\n",
    "    try:\n",
    "        if pd.isna(seq_str) or seq_str == '' or seq_str == 'nan':\n",
    "            return {k:0 for k in [\n",
    "                'seq_length','seq_mean','seq_std','seq_min','seq_max','seq_median','seq_sum',\n",
    "                'seq_skew','seq_kurt','seq_q25','seq_q75','seq_iqr','seq_range',\n",
    "                'seq_unique_count','seq_unique_ratio','seq_positive_count','seq_negative_count',\n",
    "                'seq_zero_count','seq_trend','seq_volatility']}\n",
    "        seq_arr = np.fromstring(seq_str, sep=',', dtype=np.float32)\n",
    "        if len(seq_arr)==0:\n",
    "            return {k:0 for k in [\n",
    "                'seq_length','seq_mean','seq_std','seq_min','seq_max','seq_median','seq_sum',\n",
    "                'seq_skew','seq_kurt','seq_q25','seq_q75','seq_iqr','seq_range',\n",
    "                'seq_unique_count','seq_unique_ratio','seq_positive_count','seq_negative_count',\n",
    "                'seq_zero_count','seq_trend','seq_volatility']}\n",
    "        mean_val = np.mean(seq_arr)\n",
    "        std_val = np.std(seq_arr) if len(seq_arr)>1 else 0\n",
    "        q25,q50,q75 = np.percentile(seq_arr,[25,50,75])\n",
    "        try:\n",
    "            from scipy import stats\n",
    "            skew_val = stats.skew(seq_arr) if len(seq_arr)>1 else 0\n",
    "            kurt_val = stats.kurtosis(seq_arr) if len(seq_arr)>1 else 0\n",
    "        except:\n",
    "            skew_val=kurt_val=0\n",
    "        trend = np.polyfit(np.arange(len(seq_arr)), seq_arr,1)[0] if len(seq_arr)>2 else 0\n",
    "        volatility = np.std(np.diff(seq_arr)) if len(seq_arr)>3 else 0\n",
    "        return {\n",
    "            'seq_length': len(seq_arr),\n",
    "            'seq_mean': mean_val,'seq_std': std_val,'seq_min': np.min(seq_arr),'seq_max': np.max(seq_arr),\n",
    "            'seq_median': q50,'seq_sum': np.sum(seq_arr),'seq_skew': skew_val,'seq_kurt': kurt_val,\n",
    "            'seq_q25': q25,'seq_q75': q75,'seq_iqr': q75-q25,'seq_range': np.max(seq_arr)-np.min(seq_arr),\n",
    "            'seq_unique_count': len(np.unique(seq_arr)),\n",
    "            'seq_unique_ratio': len(np.unique(seq_arr))/len(seq_arr),\n",
    "            'seq_positive_count': np.sum(seq_arr>0),\n",
    "            'seq_negative_count': np.sum(seq_arr<0),\n",
    "            'seq_zero_count': np.sum(seq_arr==0),\n",
    "            'seq_trend': trend,\n",
    "            'seq_volatility': volatility\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in seq feature extraction: {e}\")\n",
    "        return {k:0 for k in [\n",
    "            'seq_length','seq_mean','seq_std','seq_min','seq_max','seq_median','seq_sum',\n",
    "            'seq_skew','seq_kurt','seq_q25','seq_q75','seq_iqr','seq_range',\n",
    "            'seq_unique_count','seq_unique_ratio','seq_positive_count','seq_negative_count',\n",
    "            'seq_zero_count','seq_trend','seq_volatility']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbbf3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interaction_features(df, cat_cols):\n",
    "    interaction_features = []\n",
    "    for i, col1 in enumerate(cat_cols):\n",
    "        for col2 in cat_cols[i+1:]:\n",
    "            if col1 in df.columns and col2 in df.columns:\n",
    "                new_col = f\"{col1}_{col2}_interaction\"\n",
    "                df[new_col] = df[col1].astype(str) + \"_\" + df[col2].astype(str)\n",
    "                interaction_features.append(new_col)\n",
    "    le = LabelEncoder()\n",
    "    for col in interaction_features:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df, interaction_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b8c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_features(df):\n",
    "    if 'hour' in df.columns:\n",
    "        try:\n",
    "            df['hour'] = pd.to_numeric(df['hour'], errors='coerce').fillna(0).astype(int)\n",
    "            df['is_morning'] = ((df['hour'] >=6) & (df['hour']<12)).astype(int)\n",
    "            df['is_afternoon'] = ((df['hour']>=12)&(df['hour']<18)).astype(int)\n",
    "            df['is_evening'] = ((df['hour']>=18)&(df['hour']<24)).astype(int)\n",
    "            df['is_night'] = ((df['hour']>=0)&(df['hour']<6)).astype(int)\n",
    "            df['is_peak_hour'] = df['hour'].isin([9,10,11,14,15,16,19,20,21]).astype(int)\n",
    "            df['hour_sin'] = np.sin(2*np.pi*df['hour']/24)\n",
    "            df['hour_cos'] = np.cos(2*np.pi*df['hour']/24)\n",
    "        except:\n",
    "            pass\n",
    "    if 'day_of_week' in df.columns:\n",
    "        try:\n",
    "            df['day_of_week'] = pd.to_numeric(df['day_of_week'], errors='coerce').fillna(0).astype(int)\n",
    "            df['is_weekend'] = df['day_of_week'].isin([5,6]).astype(int)\n",
    "            df['is_monday'] = (df['day_of_week']==0).astype(int)\n",
    "            df['is_friday'] = (df['day_of_week']==4).astype(int)\n",
    "            df['dow_sin'] = np.sin(2*np.pi*df['day_of_week']/7)\n",
    "            df['dow_cos'] = np.cos(2*np.pi*df['day_of_week']/7)\n",
    "        except:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c031902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(df, feature_cols, seq_col, is_train=True, target_encoders=None):\n",
    "    if seq_col in df.columns:\n",
    "        seq_stats = df[seq_col].astype(str).apply(extract_seq_features)\n",
    "        seq_features = pd.DataFrame(seq_stats.tolist(), index=df.index)\n",
    "        df = pd.concat([df.drop(columns=[seq_col]), seq_features], axis=1)\n",
    "    cat_cols = [\"gender\",\"age_group\",\"inventory_id\",\"day_of_week\",\"hour\"]\n",
    "    df, interaction_features = create_interaction_features(df, cat_cols)\n",
    "    df = create_time_features(df)\n",
    "    if is_train and 'clicked' in df.columns:\n",
    "        for col in cat_cols:\n",
    "            if col in df.columns:\n",
    "                try:\n",
    "                    target_mean = df.groupby(col)['clicked'].mean()\n",
    "                    df[f'{col}_target_mean'] = df[col].map(target_mean).fillna(df['clicked'].mean())\n",
    "                except:\n",
    "                    pass\n",
    "    elif target_encoders is not None:\n",
    "        for col, encoder_dict in target_encoders.items():\n",
    "            if col in df.columns and encoder_dict:\n",
    "                df[f'{col}_target_mean'] = df[col].map(encoder_dict).fillna(0.5)\n",
    "    new_feature_cols = [col for col in df.columns if col not in ['clicked','ID']]\n",
    "    return df, new_feature_cols\n",
    "\n",
    "def encode_categorical_features(df, cat_cols):\n",
    "    for col in cat_cols:\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                freq_encoding = df[col].value_counts().to_dict()\n",
    "                df[f'{col}_freq'] = df[col].map(freq_encoding).fillna(0)\n",
    "                df[col] = df[col].astype('category').cat.codes\n",
    "            except:\n",
    "                df[col] = 0\n",
    "                df[f'{col}_freq'] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836258a3",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fab54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_xgb_params(X_train, y_train, X_val, y_val):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"auc\",\n",
    "            \"booster\": \"gbtree\",\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\",0.01,0.2),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\",3,12),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\",1,10),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\",0.4,1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\",0.4,1.0),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\",0.0,5.0),\n",
    "            \"lambda\": trial.suggest_float(\"lambda\",0.0,5.0),\n",
    "            \"alpha\": trial.suggest_float(\"alpha\",0.0,5.0),\n",
    "            \"seed\": CFG['SEED']\n",
    "        }\n",
    "        dtrain = xgb.DMatrix(X_train,label=y_train)\n",
    "        dval = xgb.DMatrix(X_val,label=y_val)\n",
    "        bst = xgb.train(\n",
    "            params,dtrain,num_boost_round=1000,\n",
    "            evals=[(dval,\"val\")],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        preds = bst.predict(dval)\n",
    "        auc = roc_auc_score(y_val,preds)\n",
    "        return auc\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=CFG['SEED']))\n",
    "    study.optimize(objective,n_trials=CFG['OPTUNA_TRIALS'], show_progress_bar=True)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbc0f2d",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282e3f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_data(df):\n",
    "    clicked_1 = df[df['clicked']==1]\n",
    "    clicked_0 = df[df['clicked']==0]\n",
    "    if len(clicked_0) > len(clicked_1)*3:\n",
    "        clicked_0 = clicked_0.sample(n=len(clicked_1)*3, random_state=CFG['SEED'])\n",
    "    return pd.concat([clicked_1,clicked_0],axis=0).sample(frac=1,random_state=CFG['SEED']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce9e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_with_cv(data_path):\n",
    "    dataset = ds.dataset(data_path, format=\"parquet\")\n",
    "    models=[]\n",
    "    feature_names=None\n",
    "    target_encoders={}\n",
    "    batch_num=0\n",
    "    best_params=None\n",
    "    for batch in dataset.to_batches(batch_size=CFG['BATCH_SIZE']):\n",
    "        batch_num+=1\n",
    "        df = batch.to_pandas()\n",
    "        df = downsample_data(df)\n",
    "        feature_cols = [c for c in df.columns if c not in {'clicked','seq','ID'}]\n",
    "        df, feature_cols = preprocess_features(df, feature_cols,'seq',is_train=True)\n",
    "        if batch_num==1:\n",
    "            cat_cols = [\"gender\",\"age_group\",\"inventory_id\",\"day_of_week\",\"hour\"]\n",
    "            for col in cat_cols:\n",
    "                if col in df.columns and 'clicked' in df.columns:\n",
    "                    try:\n",
    "                        target_encoders[col] = df.groupby(col)['clicked'].mean().to_dict()\n",
    "                    except:\n",
    "                        target_encoders[col] = {}\n",
    "        df = encode_categorical_features(df, [\"gender\",\"age_group\",\"inventory_id\",\"day_of_week\",\"hour\"])\n",
    "        available_features = [col for col in feature_cols if col in df.columns]\n",
    "        if feature_names is None:\n",
    "            feature_names = available_features.copy()\n",
    "        X = df[available_features].fillna(0)\n",
    "        y = df['clicked']\n",
    "        if batch_num==1:\n",
    "            sample_size = min(50000,len(X))\n",
    "            sample_indices = np.random.choice(len(X), sample_size, replace=False)\n",
    "            X_sample = X.iloc[sample_indices]\n",
    "            y_sample = y.iloc[sample_indices]\n",
    "            X_temp,X_val_temp,y_temp,y_val_temp = train_test_split(\n",
    "                X_sample,y_sample,test_size=0.2,random_state=CFG['SEED'], stratify=y_sample\n",
    "            )\n",
    "            best_params = optimize_xgb_params(X_temp,y_temp,X_val_temp,y_val_temp)\n",
    "            del X_temp,X_val_temp,y_temp,y_val_temp,X_sample,y_sample\n",
    "        skf = StratifiedKFold(n_splits=CFG['N_FOLDS'], shuffle=True, random_state=CFG['SEED'])\n",
    "        fold_aucs=[]\n",
    "        for fold,(train_idx,val_idx) in enumerate(skf.split(X,y)):\n",
    "            X_train,X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train,y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            dtrain = xgb.DMatrix(X_train,label=y_train)\n",
    "            dval = xgb.DMatrix(X_val,label=y_val)\n",
    "            model = xgb.train(\n",
    "                best_params or {\n",
    "                    \"objective\":\"binary:logistic\",\n",
    "                    \"eval_metric\":\"auc\",\n",
    "                    \"learning_rate\":CFG['LEARNING_RATE'],\n",
    "                    \"max_depth\":6,\n",
    "                    \"subsample\":0.8,\n",
    "                    \"colsample_bytree\":0.8,\n",
    "                    \"seed\":CFG['SEED']\n",
    "                },\n",
    "                dtrain,\n",
    "                num_boost_round=CFG['NUM_BOOST_ROUND'],\n",
    "                evals=[(dtrain,\"train\"),(dval,\"valid\")],\n",
    "                early_stopping_rounds=CFG['EARLY_STOPPING'],\n",
    "                verbose_eval=100\n",
    "            )\n",
    "            val_pred = model.predict(dval)\n",
    "            fold_auc = roc_auc_score(y_val,val_pred)\n",
    "            fold_aucs.append(fold_auc)\n",
    "            models.append(model)\n",
    "        print(f\"Batch {batch_num} Average CV AUC: {np.mean(fold_aucs):.4f} (+/- {np.std(fold_aucs):.4f})\")\n",
    "        del df,X,y\n",
    "        gc.collect()\n",
    "    return models, feature_names, target_encoders\n",
    "\n",
    "models, feature_names, target_encoders = train_xgb_with_cv(\"./data/train.parquet\")\n",
    "print(\"=== High Performance XGBoost CTR Prediction ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5967efc3",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c771f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_data(models,test_path,feature_names,target_encoders):\n",
    "    test_df = pd.read_parquet(test_path, engine=\"pyarrow\")\n",
    "    if 'ID' in test_df.columns:\n",
    "        test_ids = test_df['ID'].copy()\n",
    "        test_df = test_df.drop(columns=['ID'])\n",
    "    feature_cols = [c for c in test_df.columns if c!='seq']\n",
    "    test_df, feature_cols = preprocess_features(test_df, feature_cols,'seq',is_train=False,target_encoders=target_encoders)\n",
    "    test_df = encode_categorical_features(test_df, [\"gender\",\"age_group\",\"inventory_id\",\"day_of_week\",\"hour\"])\n",
    "    for feature in feature_names:\n",
    "        if feature not in test_df.columns:\n",
    "            test_df[feature]=0\n",
    "    test_features = test_df[feature_names].fillna(0)\n",
    "    predictions = np.zeros(len(test_df))\n",
    "    for model in models:\n",
    "        dtest = xgb.DMatrix(test_features)\n",
    "        predictions += model.predict(dtest)\n",
    "    predictions /= len(models)\n",
    "    return predictions\n",
    "\n",
    "test_predictions = predict_test_data(models,\"./data/test.parquet\",feature_names,target_encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5347d4e9",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb05b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['clicked'] = test_predictions\n",
    "submission.to_csv('./high_performance_xgb_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
